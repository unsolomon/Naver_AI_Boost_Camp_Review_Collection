# ğŸ§  NLP Recent Trends â€” NAVER Boostcamp AI Tech  
> Instructor: ì¡°í˜¸ì¤€ (KAIST Ph.D Candidate)  
> Summary by: ì •ë¦¬ë³¸ (NAVER Connect Foundation, 2024)  
> ë¹„ì˜ë¦¬ì  êµìœ¡ ë° ë³µìŠµìš© ì •ë¦¬  

---

## ğŸ“˜ ê°•ì˜ êµ¬ì„±

| ê°•ì˜ | ì£¼ì œ | í•µì‹¬ í‚¤ì›Œë“œ |
|------|------|--------------|
| [1ê°•](#1ï¸âƒ£-reasoning--planning) | Reasoning & Planning | CoT, ReAct, Decomposition |
| [2ê°•](#2ï¸âƒ£-llm-applications--agents) | LLM Applications & Agents | Auto-GPT, Visual ChatGPT, LLM-Planner |
| [3ê°•](#3ï¸âƒ£-ethics--responsible-llms) | Ethics & Responsible LLMs | Hallucination, Bias, Privacy |
| [4ê°•](#4ï¸âƒ£-knowledge-update--continual-learning--rag) | Knowledge Update | Temporal Misalignment, Continual Learning, RAG |
| [5ê°•](#5ï¸âƒ£-llm-providers--applications--deployment) | LLM Market & Deployment | Open vs Proprietary, Copilot, LangChain |

---

## 1ï¸âƒ£ Reasoning & Planning  
> From Chain-of-Thought to ReAct â€” Prompting-based Reasoning Strategies

### ğŸ”¹ ì£¼ìš” ë‚´ìš©
- **LLMì€ ì‚¬ê³ (thinking)ê°€ ì•„ë‹ˆë¼ ì˜ˆì¸¡(prediction)**  
  â†’ Reasoningê³¼ Planning ê¸°ë²•ì„ í†µí•´ â€œìƒê°í•˜ëŠ” ëª¨ë¸â€ì²˜ëŸ¼ ë™ì‘í•˜ê²Œ í•¨.
- **Chain-of-Thought (CoT)**: ë¬¸ì œ í•´ê²° ê³¼ì •ì„ ë‹¨ê³„ì ìœ¼ë¡œ í‘œí˜„í•´ Reasoning ìœ ë„.
- **Zero-shot CoT**: `"Let's think step by step"` ë¬¸êµ¬ë§Œìœ¼ë¡œë„ ì¶”ë¡  ê°€ëŠ¥.
- **Self-Consistency (SC)**: ì—¬ëŸ¬ Reasoning ê²°ê³¼ ì¤‘ ë‹¤ìˆ˜ê²°ë¡œ ì •ë‹µ ê²°ì •.
- **Least-to-Most Prompting**: ì‰¬ìš´ ë¬¸ì œë¶€í„° ë‚œì´ë„ ìˆœì°¨ í•´ê²°.
- **Decomposed Prompting**: ë¬¸ì œë¥¼ í•˜ìœ„ ëª¨ë“ˆ ë‹¨ìœ„ë¡œ ë¶„í•´í•´ í•´ê²°.
- **ReAct**: Reasoning + Acting ê²°í•© (ë„êµ¬ ì‚¬ìš©ê³¼ ì¶”ë¡ ì„ í†µí•©).

### ğŸ§© í•µì‹¬ ìš”ì•½
| ê¸°ë²• | ê°œë… | ëŒ€í‘œ ë…¼ë¬¸ |
|------|------|-------------|
| CoT | ë‹¨ê³„ì  ì¶”ë¡  | Wei et al., NeurIPS 2022 |
| Zero-shot CoT | ì˜ˆì‹œ ì—†ëŠ” ì¶”ë¡  | Kojima et al., NeurIPS 2022 |
| Self-Consistency | ë‹¤ì¤‘ ì¶”ë¡  ê²°í•© | Wang et al., ICLR 2023 |
| Least-to-Most | ë‹¨ê³„ì  ë¬¸ì œ ë¶„í•´ | Zhou et al., ICLR 2023 |
| ReAct | Reason + Acting | Yao et al., ICLR 2023 |

---

## 2ï¸âƒ£ LLM Applications & Agents  
> From Auto-GPT to LLM-Planner â€” How Agents Think and Act

### ğŸ”¹ ì£¼ìš” ë‚´ìš©
- **LLM Agent**: ìŠ¤ìŠ¤ë¡œ ê³„íšì„ ì„¸ìš°ê³  ë„êµ¬ë¥¼ í™œìš©í•´ ë¬¸ì œ í•´ê²° (ì˜ˆ: Auto-GPT).  
- **Visual ChatGPT**: ChatGPT + Visual Foundation Models (VFM) â†’ ì´ë¯¸ì§€ ìƒì„±/í¸ì§‘.
- **JARVIS (HuggingGPT)**: ChatGPTê°€ HuggingFace ëª¨ë¸ë“¤ì„ ì¡°ìœ¨í•˜ë©° ë³µí•© ì‘ì—… ìˆ˜í–‰.
- **LLM-Planner**: ì–¸ì–´ ê¸°ë°˜ ë¡œë´‡ í–‰ë™ ê³„íš (Few-shot Grounded Planning).
- **Generative Agents**: ì¸ê°„ ì‚¬íšŒë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” LLM ê¸°ë°˜ ì—ì´ì „íŠ¸.
- **RAG ê¸°ë°˜ ë³´ê°•í˜• ì—ì´ì „íŠ¸**ë¡œ ë°œì „ ì¤‘.

### ğŸ§  ì „ì²´ ìš”ì•½

| ë¶„ë¥˜ | ì£¼ìš” ì—°êµ¬ | í•µì‹¬ ì•„ì´ë””ì–´ |
|------|------------|----------------|
| Auto-GPT | Self-Planning LLM | ì™¸ë¶€ ë„êµ¬ í˜¸ì¶œ ë° ì‹¤í–‰ |
| Visual ChatGPT | ë©€í‹°ëª¨ë‹¬ í™•ì¥ | VFM + ChatGPT ìœµí•© |
| JARVIS | Model Orchestration | LLMì´ ë‹¤ë¥¸ ëª¨ë¸ ì¡°ìœ¨ |
| LLM-Planner | Embodied Agent | ì–¸ì–´ â†’ í–‰ë™ ê³„íš |
| Generative Agents | ì¸ê°„ ì‹œë®¬ë ˆì´ì…˜ | ê¸°ì–µ-ê³„íš-í–‰ë™ ë£¨í”„ |

---

## 3ï¸âƒ£ Ethics & Responsible LLMs  
> Building Safe, Fair, and Private Large Language Models

### âš–ï¸ ì£¼ìš” ì´ìŠˆ
| êµ¬ë¶„ | ì„¤ëª… | ì£¼ìš” ëŒ€ì‘ |
|------|------|------------|
| **Hallucination** | ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ ì •ë³´ ìƒì„± | TruthfulQA, RAG |
| **Toxicity** | ê³µê²©ì  í…ìŠ¤íŠ¸ ìƒì„± | Perspective API, Fine-tuning |
| **Bias** | ì‚¬íšŒì  í¸í–¥ ë°˜ì˜ | CrowS-Pairs, StereoSet, Self-Debiasing |
| **Privacy** | í•™ìŠµ ì¤‘ ê°œì¸ì •ë³´ ìœ ì¶œ | Deduplication, Knowledge Unlearning |

### ğŸ”¹ í•µì‹¬ ê¸°ë²•
- **Self-Diagnosis & Self-Debiasing**  
  â†’ ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ í¸í–¥ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ê³  ìˆ˜ì •.  
- **Knowledge Unlearning**  
  â†’ â€œìŠí ê¶Œë¦¬(Right to be Forgotten)â€ ì‹¤í˜„ì„ ìœ„í•œ ì„ íƒì  ì§€ì‹ ì‚­ì œ.  
- **Ethical Fine-tuning**  
  â†’ ì•ˆì „ì„±ê³¼ ì‹ ë¢°ì„± ê°•í™”ìš© Fine-tuning ë³´ìƒ ì‹ í˜¸ ì¶”ê°€.

---

## 4ï¸âƒ£ Knowledge Update â€” Continual Learning & RAG  
> Overcoming Temporal Misalignment in LLMs

### ğŸ•°ï¸ Temporal Misalignment
- ì‹œê°„ì´ ì§€ë‚˜ë©´ ëª¨ë¸ì˜ ì§€ì‹ì´ ë‚¡ì•„ ì •í™•ë„ ì €í•˜.
- í•™ìŠµ ì‹œì ê³¼ í‰ê°€ ì‹œì ì´ ì–´ê¸‹ë‚ ìˆ˜ë¡ Perplexity ìƒìŠ¹ (Lazaridou et al., 2021).

### ğŸ’¥ Catastrophic Forgetting
- ìƒˆ ë°ì´í„° í•™ìŠµ ì‹œ ê¸°ì¡´ ì§€ì‹ì„ ìŠëŠ” ë¬¸ì œ.

### ğŸ” Continual Learning
| ë°©ì‹ | ê°œë… | ëŒ€í‘œ ì—°êµ¬ |
|------|------|------------|
| Regularization | íŒŒë¼ë¯¸í„° ë³€ê²½ ìµœì†Œí™” | EWC, Rec-Adam |
| Parameter Expansion | ìƒˆë¡œìš´ ëª¨ë“ˆë§Œ ì¶”ê°€ | LoRA, K-Adapter |
| Rehearsal | ê³¼ê±° ë°ì´í„° ë³µìŠµ | Mix-Review, DGR |

### ğŸ” Retrieval-Augmented Generation (RAG)
- ì™¸ë¶€ ë°ì´í„° ê²€ìƒ‰ì„ í†µí•´ ìµœì‹  ì •ë³´ë¥¼ ë°˜ì˜.
- Hallucination ì™„í™” ë° Temporal Misalignment ê°œì„ .
- í™•ì¥í˜• ê¸°ë²•: **GopherCite**, **WebGPT**, **BlenderBot 3**.

---

## 5ï¸âƒ£ LLM Providers, Applications & Deployment  
> Understanding the Commercial Landscape of LLMs

### ğŸ’¼ LLM ì‹œì¥
- AI ì‹œì¥ì€ 2030ë…„ê¹Œì§€ **740ì–µ ë‹¬ëŸ¬ ê·œëª¨** ì˜ˆìƒ.
- í•™ìŠµ ë¹„ìš©: LLaMA-65B ê¸°ì¤€ ì•½ **18ì–µ ì› ì´ìƒ**.
- ëŒ€ê¸°ì—… ì¤‘ì‹¬ â†’ ì ì°¨ Open-weight ëª¨ë¸ë¡œ ë¶„ì‚°í™”.

### ğŸ§± LLM Provider vs Application
| êµ¬ë¶„ | Provider | Application |
|------|-----------|--------------|
| ì •ì˜ | ëª¨ë¸ì„ ì§ì ‘ í•™ìŠµÂ·ì œê³µ | LLM ê¸°ë°˜ ì„œë¹„ìŠ¤ ì œì‘ |
| ëŒ€í‘œ | OpenAI, Google, Meta | MS, NAVER, Upstage |
| ì¥ì  | ë…ì ì  ê¸°ìˆ , ê³ ì„±ëŠ¥ | ë¹ ë¥¸ ìƒìš©í™”, ì ‘ê·¼ì„± |

### ğŸ§  ì£¼ìš” ëª¨ë¸
| êµ¬ë¶„ | ëª¨ë¸ëª… | íŠ¹ì§• |
|------|---------|--------|
| Proprietary | GPT-4 Turbo, Gemini, HyperCLOVA X | API ê¸°ë°˜ ìƒìš© ëª¨ë¸ |
| Open-weight | LLaMA 2, Mistral, Upstage SOLAR | ê³µê°œ ê°€ì¤‘ì¹˜ + ììœ  í™œìš© |

### âš™ï¸ LLM Deployment
- **LangChain**: LLM ì‘ìš© í†µí•© í”„ë ˆì„ì›Œí¬  
- **Quantization**: ëª¨ë¸ ê²½ëŸ‰í™” (GPTQ, AWQ, LLaMA.cpp)
- **API ê¸°ë°˜ ì„œë¹„ìŠ¤**ê°€ GPU ìì› ëŒ€ë¹„ ë” ê²½ì œì ì¼ ìˆ˜ ìˆìŒ.

---

## ğŸ”š ì „ì²´ ìš”ì•½

| Part | ì£¼ì œ | í•µì‹¬ í¬ì¸íŠ¸ |
|------|------|--------------|
| 1ê°• | Reasoning & Planning | Promptë¥¼ í†µí•œ ì‚¬ê³  ìœ ë„ |
| 2ê°• | LLM Applications & Agents | LLMì„ í–‰ë™í˜• Agentë¡œ ë°œì „ |
| 3ê°• | Ethics | ì•ˆì „í•˜ê³  ê³µì •í•œ AI ê°œë°œ |
| 4ê°• | Knowledge Update | ì§€ì†ì  í•™ìŠµ + ì™¸ë¶€ ê²€ìƒ‰ (RAG) |
| 5ê°• | LLM Trends | LLM ì‹œì¥, ì£¼ìš” ëª¨ë¸, ìƒìš©í™” ê¸°ìˆ  |

---

ğŸ“š **ì°¸ê³  ìë£Œ**
- Wei et al., *Chain-of-Thought Prompting*, NeurIPS 2022  
- Yao et al., *ReAct*, ICLR 2023  
- Lin et al., *TruthfulQA*, ACL 2022  
- Lazaridou et al., *Temporal Generalization in LMs*, NeurIPS 2021  
- Lewis et al., *Retrieval-Augmented Generation*, NeurIPS 2020  
- Gemini Team, *Gemini Models*, arXiv 2023  
- Upstage, *SOLAR 10B Release*, 2023  

---

ğŸ§¾ **ì¶œì²˜:**  
NAVER Connect Foundation â€” *NLP Recent Trends (2024)*  
ë¹„ì˜ë¦¬ì  êµìœ¡ ë° ë³µìŠµ ëª©ì ì˜ ìš”ì•½ ìë£Œì…ë‹ˆë‹¤.
