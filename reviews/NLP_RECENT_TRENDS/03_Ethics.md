# ğŸ§­ ì „ì²´ íë¦„ ìš”ì•½

| êµ¬ë¶„ | ì£¼ìš” ì´ìŠˆ | í•µì‹¬ ë‚´ìš© | ëŒ€í‘œ ì—°êµ¬ / ëŒ€ì‘ ë°©ë²• |
|------|------------|-------------|------------------------|
| ğŸŒ€ **Hallucination** | ê±°ì§“ ì •ë³´ ìƒì„± | TruthfulQA ê¸°ë°˜ í‰ê°€, RAGÂ·Prompt ê°œì„ ìœ¼ë¡œ ì™„í™” | Lin et al., ACL 2022 |
| âš ï¸ **Toxicity & Bias** | ê³µê²©ì /í¸í–¥ëœ í…ìŠ¤íŠ¸ ìƒì„± | PerspectiveAPI, CrowS-Pairs, StereoSetìœ¼ë¡œ ì¸¡ì • | Samuel et al., EMNLP 2020 / Nadeem et al., ACL 2021 |
| ğŸ§© **Bias ì™„í™”** | Self-Diagnosis & Self-Debiasing | ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ ë…ì„±/í¸ê²¬ ì¸ì‹ í›„ ì¡°ì • | Schick et al., TACL 2021 |
| ğŸ” **Privacy Invasion** | ê°œì¸ì •ë³´ ì•”ê¸° ë° ë…¸ì¶œ | Deduplication / Knowledge Unlearning | Carlini et al., USENIX 2021 |
| ğŸŒ **AI ìœ¤ë¦¬ì˜ ë°©í–¥** | ì‹ ë¢°ì„±Â·ê³µì •ì„±Â·ì•ˆì „ì„± í™•ë³´ | Alignment, Safety Fine-tuning, Unlearning | LeCun, 2023 ë“± |

---

## **1ï¸âƒ£ Hallucination (í™˜ê°)**

> LLMì´ **ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ ì •ë³´ë¥¼ ìƒì„±**í•˜ëŠ” í˜„ìƒ.  
> ì´ëŠ” ì‹ ë¢°ì„±ê³¼ ì•ˆì „ì„±ì˜ í•µì‹¬ ë¬¸ì œ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.

### ğŸ”¹ ì •ì˜
- LLMì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ ì‚¬ì‹¤ê³¼ ë‹¤ë¥¸ ì •ë³´ë¥¼ ìƒì„±í•˜ëŠ” í˜„ìƒ.  
- ì¦‰, **ê·¸ëŸ´ë“¯í•œ ê±°ì§“ë§(Confidently Wrong Answer)**.

### ğŸ”¹ ì¸¡ì • ë°©ë²• â€” TruthfulQA
> Lin et al., *TruthfulQA: Measuring How Models Mimic Human Falsehoods*, ACL 2022

- **ë°ì´í„° êµ¬ì„±**
  - 38ê°œ ì¹´í…Œê³ ë¦¬, 817ê°œ ì§ˆë¬¸
  - {ì§ˆë¬¸, ì •ë‹µ, ì˜¤ë‹µ, ì¶œì²˜} í˜•íƒœ
- **í‰ê°€ ë°©ë²•**
  - ì‚¬ëŒì´ ìƒì„±ëœ í…ìŠ¤íŠ¸ë¥¼ í‰ê°€í•˜ì—¬ Truthfulness / Informativeness ì ìˆ˜ ë¶€ì—¬
  - 0.5 ì´ìƒì´ë©´ ì°¸(True), ë¯¸ë§Œì´ë©´ ê±°ì§“(False)
- **ê²°ê³¼**
  - ëª¨ë¸ í¬ê¸°ê°€ í´ìˆ˜ë¡ Informativeness â†‘, Truthfulness â†“  
  - GPT ì‹œë¦¬ì¦ˆë³´ë‹¤ **T5 ê¸°ë°˜ UnifiedQA**ê°€ ë” ë†’ì€ ì§„ì‹¤ì„± ê¸°ë¡.

### ğŸ”¹ ìë™ í‰ê°€ ë°©ì‹
1. **Classifier ê¸°ë°˜ í‰ê°€**  
   - TruthfulQA ë°ì´í„°ë¥¼ ì´ìš©í•´ GPT-3ë¥¼ Fine-tuning â†’ ì§„ì‹¤ì„± ë¶„ë¥˜ê¸° í•™ìŠµ  
   - Accuracy ì•½ **90%**, ë¹„ìš© $100 ë‚´ì™¸.
2. **ê°ê´€ì‹ í˜•íƒœ í‰ê°€ (Perplexity ê¸°ë°˜)**  
   - ì •ë‹µ í›„ë³´ì˜ Perplexity ì¸¡ì • â†’ ê°€ì¥ ë‚®ì€ ê°’ì„ ì •ë‹µìœ¼ë¡œ ì„ íƒ  
   - ëŒ€í˜• ëª¨ë¸ì¼ìˆ˜ë¡ Truthfulness ê°ì†Œ.

### ğŸ”¹ ì™„í™” ë°©ë²•
- **Prompt ê°œì„ :** â€œThink carefully before answering.â€ ë“±ì˜ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© â†’ Truthfulness â†‘  
- **RAG (Retrieval-Augmented Generation):**  
  ì™¸ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰ í›„ ë°˜ì˜í•˜ì—¬ í™˜ê°ì„ ê°ì†Œì‹œí‚´.  
  > Chen et al., *Open-Domain QA Tutorial*, ACL 2020

---

## **2ï¸âƒ£ Toxicity & Bias**

> LLMì´ ê³µê²©ì ì´ê±°ë‚˜ ì‚¬íšŒì ìœ¼ë¡œ í¸í–¥ëœ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë¬¸ì œ.

---

### ğŸ§ª 2.1 Toxicity

> Samuel et al., *RealToxicityPrompts: Evaluating Neural Toxic Degeneration in LMs*, EMNLP 2020

#### âš™ï¸ Toxicity ì¸¡ì • â€” PerspectiveAPI
- Googleì´ ê°œë°œí•œ ë‹¤ì–¸ì–´ Toxicity í‰ê°€ API.
- ë¬¸ì¥ì— ëŒ€í•´ 8ê°œ ì†ì„±ë³„ ì ìˆ˜ ë°˜í™˜ (0~1 ë²”ìœ„).  
  - 0.5 ì´ìƒì¼ ê²½ìš° â€œToxicâ€ìœ¼ë¡œ ë¶„ë¥˜.
- **ë‹¤ì–¸ì–´ BERT + CNN** ê¸°ë°˜ìœ¼ë¡œ í›ˆë ¨ëœ ëª¨ë¸ ì‚¬ìš©.

#### ğŸ“Š LLMì˜ Toxic ê²½í–¥
- ì…ë ¥ì´ ì—†ì–´ë„ EOS í† í° ì „ê¹Œì§€ ìƒì„± ì‹œ Toxic ë°œí™” ê°€ëŠ¥.  
- 1,000 span ìƒì„± ì‹œ Toxicity 0.9ì— ë„ë‹¬.  
- Fine-tuning ë°ì´í„°(Wikipedia ë“±)ê°€ ìˆëŠ” ëª¨ë¸ì´ ê°€ì¥ ë‚®ì€ ë…ì„± ë³´ì„.

#### ğŸ“ˆ í‰ê°€ìš© ë°ì´í„° â€” RealToxicityPrompts
- Reddit ê¸°ë°˜ OpenWebTextì—ì„œ Toxicity ì ìˆ˜ ë¶„í¬ì— ë”°ë¼ 4êµ¬ê°„ ìƒ˜í”Œë§.
- Toxicí•˜ì§€ ì•Šì€ Promptë¡œ ì‹œì‘í•´ë„ ë…ì„± ë¬¸ì¥ì„ ìƒì„±í•  í™•ë¥ ì´ **80% ì´ìƒ**.
- **LLMì˜ ë…ì„± ìƒì„± ê²½í–¥ì„±ì„ ì •ëŸ‰ í‰ê°€í•˜ëŠ” ê¸°ì¤€ ë°ì´í„°ì…‹**ìœ¼ë¡œ í™œìš©.

---

### âš–ï¸ 2.2 Bias (í¸í–¥)

> Navigli et al., *Biases in Large Language Models*, JDIQ 2023

- LLMì€ ì¸í„°ë„· ê¸°ë°˜ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ë©´ì„œ **ì‚¬íšŒì  í¸ê²¬(Stereotype)**ì„ í•¨ê»˜ í•™ìŠµ.
- íŠ¹íˆ **Gender, Race, Disability, Nationality** ë“±ì—ì„œ í¸í–¥ì´ ëšœë ·í•¨.

#### ğŸ“Š Bias ì¸¡ì • ì§€í‘œ

| ë°ì´í„°ì…‹ | íŠ¹ì§• | í‰ê°€ ë°©ì‹ |
|-----------|-------|------------|
| **CrowS-Pairs** | 9ê°œ ì‚¬íšŒì  í¸í–¥, 1,508ê°œ ì˜ˆì‹œ | Stereotype ë¬¸ì¥ vs. Non-stereotype ë¬¸ì¥ì˜ Likelihood ë¹„êµ |
| **StereoSet** | Intrasentence / Intersentence í¸í–¥ êµ¬ë¶„ | Stereotypeê³¼ Anti-stereotypeì˜ Perplexity ë¹„êµ (50%ê°€ ì´ìƒì ) |

- **ì •í™•ë„ 100%** â†’ ì‹¬í•œ í¸í–¥  
- **ì •í™•ë„ 0%** â†’ ì—­í¸í–¥  
- **ì •í™•ë„ 50%** â†’ í¸í–¥ ì—†ìŒ (ì´ìƒì  ìƒíƒœ)

---

### ğŸ§© 2.3 Toxicity & Bias ì™„í™”

#### ğŸ§  Fine-tuning / Alignment
> Touvron et al., *LLAMA2: Open Foundation and Fine-tuned Chat Models*, arXiv 2023  
- Model alignment ê³¼ì •ì—ì„œ **Safety ë³´ìƒ ì‹ í˜¸** ì¶”ê°€ í•™ìŠµ  
- ì‚¬ìš©ì ìœ í•´ ì…ë ¥ì— ëŒ€í•´ ì•ˆì „í•œ ì‘ë‹µì„ ê°•í™”.

#### ğŸ§° Logit Bias (ë‹¨ìˆœ í•„í„°ë§)
> [OpenAI API logit_bias](https://platform.openai.com/docs/api-reference/completions/create#completions-create-logit_bias)
- íŠ¹ì • í† í°ì˜ ìƒì„± í™•ë¥ ì„ ë‚®ì¶”ê±°ë‚˜ ì œê±° (`-âˆ` ê°€ì¤‘ì¹˜ ì ìš©)
- í•œê³„:  
  - ë‹¤ë‹¨ì–´ í‘œí˜„ ì²˜ë¦¬ ë¶ˆê°€  
  - ë¬¸ë§¥ì  ë…ì„± êµ¬ë¶„ ì–´ë ¤ì›€  

#### ğŸ”„ Self-Diagnosis & Self-Debiasing
> Schick et al., *Self-Diagnosis and Self-Debiasing*, TACL 2021

##### Step 1ï¸âƒ£ Self-Diagnosis
- ëª¨ë¸ì´ ìŠ¤ìŠ¤ë¡œ ìƒì„±ë¬¸ì¥ì˜ Toxicityë¥¼ íŒë‹¨.  
- `"Does the above text contain toxicity?"`  
- Perspective API ë¼ë²¨ê³¼ì˜ ì •í™•ë„ ë¹„êµ ì‹œ, ëª¨ë¸ í¬ê¸°â†‘ â†’ ì§„ë‹¨ ì •í™•ë„â†‘.

##### Step 2ï¸âƒ£ Self-Debiasing
- Biased tokenì˜ í™•ë¥ ì„ ì¤„ì´ëŠ” ë°©ì‹ìœ¼ë¡œ Decoding ìˆ˜í–‰.  
- ì˜ˆì‹œ:  
  - â€œAll terrorists are ___â€ â†’ â€œMuslimsâ€ì˜ í™•ë¥ ì„ ë‚®ì¶”ì–´ ëŒ€ì²´ ë‹¨ì–´ ìƒì„±.  
- RealToxicityPrompts ê¸°ì¤€ìœ¼ë¡œ Perplexity ìœ ì§€í•˜ë©° Toxicity ê°ì†Œ.

---

## **3ï¸âƒ£ Privacy Invasion (ê°œì¸ì •ë³´ ì¹¨í•´)**

> Carlini et al., *Extracting Training Data from LLMs*, USENIX 2021

### ğŸ” ì •ì˜
- LLMì´ í•™ìŠµ ë°ì´í„° ì† **ê°œì¸ ì •ë³´ë¥¼ ì•”ê¸°(Memorization)**í•˜ì—¬ ê·¸ëŒ€ë¡œ ì¬ìƒì„±í•˜ëŠ” ë¬¸ì œ.

### ğŸ“‰ ì‚¬ë¡€: GPT-2 Memorization
- 20ë§Œ ê°œ ìƒ˜í”Œ ì¤‘ 1,800ê°œë¥¼ Membership Inference Attackìœ¼ë¡œ ë³µì›.  
- êµ¬ê¸€ ê²€ìƒ‰ ê²°ê³¼ì™€ ì¼ì¹˜í•œ 604ê°œ í…ìŠ¤íŠ¸ â†’ ì‹¤ì œ ê°œì¸ ì •ë³´ í¬í•¨.  
- í•™ìŠµ ë°ì´í„° ì¤‘ë³µë„ê°€ ë†’ì„ìˆ˜ë¡ Memorization í™•ë¥  ê¸‰ì¦.

---

### ğŸ§© ì™„í™” ë°©ë²•

#### 1ï¸âƒ£ **Deduplication**
> Kandpal et al., *Deduplicating Training Data Mitigates Privacy Risks*, ICML 2022  
> Lee et al., *Deduplicating Training Data Makes LMs Better*, ACL 2022

- í•™ìŠµ ë°ì´í„° ì¤‘ë³µì„ ì œê±°í•˜ë©´ Memorization í˜„ìƒ ì™„í™”.  
- ë‹¨, ì™„ì „í•œ ì¤‘ë³µ ì œê±°ë§Œìœ¼ë¡œëŠ” ê°œì¸ì •ë³´ ì¬ìƒì‚° ë°©ì§€ ë¶ˆê°€.  
- ì´ë©”ì¼ ë“± íŒ¨í„´ ê¸°ë°˜ í•„í„°ë§ í•„ìš” (e.g., `@gmail.com`).

#### 2ï¸âƒ£ **Knowledge Unlearning**
> Jang et al., *Knowledge Unlearning for Mitigating Privacy Risks*, ACL 2023

- ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ì—ì„œ íŠ¹ì • ì§€ì‹ì„ **ì„ íƒì ìœ¼ë¡œ ì œê±°(Unlearn)**.  
- â€œìŠí ê¶Œë¦¬(Right to be Forgotten)â€ êµ¬í˜„ ê°€ëŠ¥ì„±.

---

## **4ï¸âƒ£ í•µì‹¬ ì •ë¦¬**

| êµ¬ë¶„ | ë¬¸ì œ | ì£¼ìš” ëŒ€ì‘ ë°©ë²• |
|------|------|----------------|
| ğŸŒ€ Hallucination | ê±°ì§“ ì •ë³´ ìƒì„± | TruthfulQA í‰ê°€, RAG, Prompt ìµœì í™” |
| âš ï¸ Toxicity | ê³µê²©ì  í…ìŠ¤íŠ¸ ìƒì„± | Perspective API, Fine-tuning, Filtering |
| ğŸ§© Bias | ì‚¬íšŒì  í¸í–¥ ë°˜ì˜ | CrowS-Pairs, StereoSet, Self-Debiasing |
| ğŸ” Privacy | ê°œì¸ ì •ë³´ ë…¸ì¶œ | Deduplication, Knowledge Unlearning |

---

## **5ï¸âƒ£ ìœ¤ë¦¬ì  ë°©í–¥ì„± ë° ë¯¸ë˜ ê³¼ì œ**

- **LLMì˜ ì„±ëŠ¥ ë°œì „**ê³¼ í•¨ê»˜ **ì‹ ë¢°ì„±Â·ì•ˆì „ì„±Â·ê³µì •ì„±** í™•ë³´ê°€ í•„ìˆ˜.  
- **Self-aware LLM**: ìŠ¤ìŠ¤ë¡œ ë¬¸ì œë¥¼ ì¸ì‹Â·ìˆ˜ì •í•˜ëŠ” ë°©í–¥ì˜ ì—°êµ¬ê°€ í™•ëŒ€ ì¤‘.  
- í–¥í›„ í•µì‹¬ ì—°êµ¬ í‚¤ì›Œë“œ:
  - âœ… **Self-Diagnosis / Self-Debiasing**  
  - âœ… **Dynamic RAG** (ì‹¤ì‹œê°„ ê²€ì¦ ê¸°ë°˜ ìƒì„±)  
  - âœ… **Ethical Fine-tuning & Evaluation Frameworks**

---

ğŸ“š **ì°¸ê³  ë…¼ë¬¸**
- Lin et al., *TruthfulQA*, ACL 2022  
- Samuel et al., *RealToxicityPrompts*, EMNLP 2020  
- Nadeem et al., *StereoSet*, ACL 2021  
- Schick et al., *Self-Diagnosis & Self-Debiasing*, TACL 2021  
- Carlini et al., *Extracting Training Data from LLMs*, USENIX 2021  
- Kandpal et al., *Deduplication for Privacy*, ICML 2022  
- Jang et al., *Knowledge Unlearning*, ACL 2023  

---

ğŸ§¾ **ì¶œì²˜:**  
[NLP Recent Trends] Ethics (NAVER Connect Foundation, 2024)  
ë¹„ì˜ë¦¬ì  êµìœ¡ ëª©ì ì— í•œí•´ ìš”ì•½ ë° ì¬êµ¬ì„±ë¨.
