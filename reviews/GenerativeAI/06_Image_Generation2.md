# ğŸ§  Generative AI 6ê°• â€” Image Generation 2: Stable Diffusion & Evaluation

**ê°•ì‚¬:** ê°•í•„ì„± êµìˆ˜  
**ì¶œì²˜:** NAVER Connect Foundation  

---

## **1. Stable Diffusion**

### **1.1 What is Stable Diffusion?**
- **ê°œìš”**
  - 2022ë…„ 8ì›” Stability AIì—ì„œ ë°œí‘œí•œ ì˜¤í”ˆì†ŒìŠ¤ Text-to-Image ëª¨ë¸.
  - ë…¼ë¬¸ *â€œHigh-Resolution Image Synthesis with Latent Diffusion Modelsâ€ (Rombach et al., CVPR 2022)* ê¸°ë°˜ìœ¼ë¡œ ê°œë°œë¨.
  - ëŒ€ê·œëª¨ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ë°ì´í„°ì…‹ **LAION-5B**ë¡œ í•™ìŠµ.
  - **Latent Diffusion Model (LDM)** êµ¬ì¡°ë¥¼ ê°œì„ í•˜ì—¬, íš¨ìœ¨ì ì¸ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ìƒì„±ì„ êµ¬í˜„.

- **í•µì‹¬ ê°œë…**
  - ì§ì ‘ì ì¸ ì´ë¯¸ì§€ í”½ì…€ í•™ìŠµì´ ì•„ë‹Œ **ì ì¬ ê³µê°„(latent space)**ì—ì„œ ì—°ì‚° ìˆ˜í–‰.
  - í•™ìŠµ ë° ì¶”ë¡  íš¨ìœ¨ì„± í–¥ìƒ, ì—°ì‚° ë¹„ìš© ê°ì†Œ, ë¹ ë¥¸ ìƒì„± ì†ë„ í™•ë³´.

---

### **1.2 Stable Diffusion Architecture**
Stable Diffusionì€ 3ê°€ì§€ ì£¼ìš” ì»´í¬ë„ŒíŠ¸ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.

#### **(1) Autoencoder**
- ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì••ì¶•í•´ ì €ì°¨ì› ì ì¬ ë²¡í„°ë¡œ ë³€í™˜.
- **Encoder:** ì´ë¯¸ì§€ â†’ Latent  
- **Decoder:** Latent â†’ ì´ë¯¸ì§€ ë³µì›
- ì ì¬ ê³µê°„ì˜ í¬ê¸°: `(H/f Ã— W/f Ã— 4)`  
- í•™ìŠµ ë¹„ìš©ì„ ì ˆê°í•˜ê³  ë¹ ë¥¸ í•™ìŠµ ê°€ëŠ¥.

#### **(2) Image Information Creator (U-Net + Noise Scheduler)**
- **U-Net:** ë…¸ì´ì¦ˆë¥¼ ì˜ˆì¸¡í•˜ëŠ” í•µì‹¬ ë„¤íŠ¸ì›Œí¬.
- **Noise Scheduler:** ì‹œì ë³„ë¡œ ë…¸ì´ì¦ˆ ì–‘ì„ ì œì–´.
- ì…ë ¥: `latent + noise + timestep`
- ì¶œë ¥: ë…¸ì´ì¦ˆ ì˜ˆì¸¡ê°’ â†’ ì‹¤ì œ ë…¸ì´ì¦ˆì™€ì˜ MSE ì†ì‹¤ë¡œ í•™ìŠµ.

#### **(3) Text Encoder**
- í…ìŠ¤íŠ¸ë¥¼ í† í° ë‹¨ìœ„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜.
- **CLIP Text Encoder** ì‚¬ìš© (BERT ëŒ€ë¹„ ë” ë‚˜ì€ í’ˆì§ˆ).
- ì…ë ¥ ë¬¸ì¥ì€ 77ê°œ í† í°ìœ¼ë¡œ ë§ì¶° padding í›„ `[B, 77, 768]` í˜•íƒœë¡œ ì„ë² ë”©.
- **Cross-Attention**ì„ í†µí•´ í…ìŠ¤íŠ¸ ì •ë³´(Key, Value)ì™€ ë…¸ì´ì¦ˆ ì ì¬ê°’(Query)ì„ ê²°í•©.

> âœ… Stable Diffusion 2ì—ì„œëŠ” ë” ëŒ€í˜• ëª¨ë¸ **OpenCLIP**ì„ ì±„íƒí•˜ì—¬ ìƒì„± í’ˆì§ˆ í–¥ìƒ.

---

## **1.3 Training Stable Diffusion**

### **í•™ìŠµ í™˜ê²½**
- **Dataset:** LAION-2B (256Ã—256 pretrain), LAION-5B (512Ã—512 fine-tune)
- **Text Encoder:** CLIP ViT-L/14 (63M)
- **U-Net:** 860M parameters
- **Hardware:** 32Ã—8Ã—A100 GPU
- **Batch Size:** 2048

### **í•™ìŠµ ê³¼ì •**
1. ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ ê°ê° Encoderë¡œ ë³€í™˜ â†’ latent & token embedding ìƒì„±  
2. latentì— ë¬´ì‘ìœ„ timestepì— ë”°ë¼ ë…¸ì´ì¦ˆ ì¶”ê°€ (Noise Scheduler)
3. U-Netì— `noisy latent + time embedding + token embedding` ì…ë ¥
4. ì˜ˆì¸¡ëœ ë…¸ì´ì¦ˆì™€ ì‹¤ì œ ë…¸ì´ì¦ˆì˜ MSEë¥¼ ê³„ì‚°í•˜ì—¬ ì—­ì „íŒŒ(backprop)
5. ë…¸ì´ì¦ˆ ì œê±° ëŠ¥ë ¥ì„ ì ì§„ì ìœ¼ë¡œ í•™ìŠµ

---

## **1.4 Inference (ì¶”ë¡ )**

### **Text-to-Image**
- ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆì—ì„œ ì‹œì‘.
- ì…ë ¥ í…ìŠ¤íŠ¸ ì„ë² ë”©ê³¼ í•¨ê»˜ U-Netì„ í†µí•´ ë°˜ë³µì ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°.
- ìµœì¢… latentë¥¼ Decoderë¡œ ë³µì› â†’ ê³ í•´ìƒë„ ì´ë¯¸ì§€ ìƒì„±.

### **Inpainting**
- ê¸°ì¡´ ì´ë¯¸ì§€ì—ì„œ latentë¥¼ ì¶”ì¶œ í›„ ì¼ë¶€ ì˜ì—­ì—ë§Œ ë…¸ì´ì¦ˆë¥¼ ì¶”ê°€.
- ì‘ì€ timestep â†’ ì›ë³¸ ì´ë¯¸ì§€ ìœ ì§€, í° timestep â†’ ìƒˆë¡­ê²Œ ë³€í˜•.
- ì´í›„ Text-to-Imageì™€ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì˜ˆì¸¡ ë° ë³µì›.

---

## **2. After Stable Diffusion**

### **2.1 Stable Diffusion 2**
- **ë°œí‘œ:** 2022ë…„ 11ì›”  
- **ê°œì„ ì :**
  - í•´ìƒë„: `512Ã—512 â†’ 768Ã—768`
  - Text Encoder: CLIP â†’ **OpenCLIP**
  - **v-prediction ë°©ì‹** ë„ì…ìœ¼ë¡œ í•™ìŠµ ì•ˆì •ì„± í–¥ìƒ ë° ì„±ëŠ¥ ê°œì„ .
  - **Super-Resolution Upscaler Diffusion Model** ì¶”ê°€ â†’ ìµœëŒ€ 2048Ã—2048 ê³ í•´ìƒë„ ì´ë¯¸ì§€ ìƒì„± ê°€ëŠ¥.
  - **Depth2Img:** ê¹Šì´ ë§µ(Depth map) ê¸°ë°˜ ì´ë¯¸ì§€ ìƒì„± ê¸°ëŠ¥ ì¶”ê°€.

---

### **2.2 Stable Diffusion XL (SDXL)**
- **ë°œí‘œ:** 2023ë…„ 7ì›”  
- **íŠ¹ì§•:**
  - Two-Stage êµ¬ì¡° (Base + Refiner)
  - í•´ìƒë„ 1024Ã—1024 ì´ë¯¸ì§€ ìƒì„± ê°€ëŠ¥
  - Text Encoder 2ê°œ ì‚¬ìš© â†’ ë” ì •êµí•œ í”„ë¡¬í”„íŠ¸ ë°˜ì˜
  - íŒŒë¼ë¯¸í„° ìˆ˜ ì¦ê°€ (865M â†’ 2.6B)
  - ë‹¤ì–‘í•œ ë¹„ìœ¨(Multi-Aspect) ì´ë¯¸ì§€ ìƒì„± ê°€ëŠ¥
  - Autoencoder ê°œì„  â†’ ê³ ì£¼íŒŒ(high-frequency) ë””í…Œì¼ ë³´ì¡´

> ë…¼ë¬¸: *SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis (Dustin Podell et al., 2023)*

---

### **2.3 SDXL Turbo**
- **ë°œí‘œ:** 2023ë…„ 11ì›”  
- **í•µì‹¬ ê¸°ìˆ :** *Adversarial Diffusion Distillation (ADD)*  
- **íŠ¹ì§•:**
  - ê¸°ì¡´ SDXLë³´ë‹¤ í›¨ì”¬ ë¹ ë¥¸ **One-Step Generation**
  - ë‹¨ 1-stepì—ì„œë„ ë†’ì€ í’ˆì§ˆì˜ ê²°ê³¼ ìƒì„±
  - 4-step generationì—ì„œëŠ” ë‹¤ë‹¨ê³„ ëª¨ë¸ë³´ë‹¤ ë†’ì€ ì„±ëŠ¥ ê¸°ë¡
  - ë¹ ë¥¸ ìƒì„± ì†ë„ + ë†’ì€ ì •í•©ë„ ìœ ì§€

> ë…¼ë¬¸: *Adversarial Diffusion Distillation (Axel Sauer et al., 2023)*

---

## **3. Evaluation Metrics**

### **3.1 Inception Score (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)**
- ìƒì„±ëœ ì´ë¯¸ì§€ì˜ **í’ˆì§ˆ(Fidelity)**ê³¼ **ë‹¤ì–‘ì„±(Diversity)**ì„ ë™ì‹œì— í‰ê°€.
- **Inception v3** ëª¨ë¸ë¡œ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ì—¬ í´ë˜ìŠ¤ í™•ë¥  ë¶„í¬ ê³„ì‚°.
- ë‘ ë¶„í¬ì˜ **KL Divergence**ë¡œ ì ìˆ˜ë¥¼ ê³„ì‚°:
  - \( IS = \exp(\mathbb{E}_x [ KL(p(y|x) || p(y)) ]) \)
- Classê°€ ëª…í™•í•˜ê³ , ë‹¤ì–‘í•œ classê°€ ì¡´ì¬í• ìˆ˜ë¡ ì ìˆ˜ê°€ ë†’ìŒ.

---

### **3.2 FID (Frechet Inception Distance) Score (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)**
- ì‹¤ì œ ì´ë¯¸ì§€ì™€ ìƒì„± ì´ë¯¸ì§€ì˜ ì„ë² ë”© ë¶„í¬ ì°¨ì´ë¥¼ ì¸¡ì •.
- **Inception Network**ë¡œ ì–»ì€ feature embedding ì‚¬ìš©.
- ë‘ ë¶„í¬ì˜ **í”„ë ˆì³‡ ê±°ë¦¬(Frechet distance)**ë¥¼ ê³„ì‚°:
  - \( FID = || \mu_r - \mu_g ||^2 + Tr(\Sigma_r + \Sigma_g - 2(\Sigma_r \Sigma_g)^{1/2}) \)
- ë‚®ì„ìˆ˜ë¡ ì‹¤ì œ ì´ë¯¸ì§€ì™€ ìœ ì‚¬í•¨.

---

### **3.3 CLIP Score (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)**
- ì´ë¯¸ì§€ì™€ ìº¡ì…˜(í…ìŠ¤íŠ¸) ê°„ì˜ ì˜ë¯¸ì  ì¼ì¹˜ë„ë¥¼ í‰ê°€.
- **CLIP ëª¨ë¸**ì„ ì´ìš©í•´ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê°ê°ì„ ì„ë² ë”©í•˜ê³ ,
  ë‘ ë²¡í„°ì˜ **Cosine Similarity**ë¡œ ì ìˆ˜ë¥¼ ê³„ì‚°.
- Reference-free metricìœ¼ë¡œ, Caption ì—†ì´ë„ ì˜ë¯¸ì  í’ˆì§ˆì„ í‰ê°€ ê°€ëŠ¥.

---

## **ğŸ“Š ìš”ì•½**

| ëª¨ë¸ | ë°œí‘œ ì‹œê¸° | ì£¼ìš” íŠ¹ì§• |
|------|------------|------------|
| Stable Diffusion | 2022.08 | Latent Diffusion ê¸°ë°˜ Text-to-Image ëª¨ë¸ |
| SD 2.0 | 2022.11 | OpenCLIP, v-prediction, ê³ í•´ìƒë„ ì—…ìŠ¤ì¼€ì¼ |
| SDXL | 2023.07 | 2-Stage êµ¬ì¡°, ì •ë°€í•œ í”„ë¡¬í”„íŠ¸ í•´ì„, 1024x1024 |
| SDXL Turbo | 2023.11 | ADD ê¸°ë°˜ One-Step ì´ˆê³ ì† ìƒì„± |

---

## **ğŸ“˜ ì°¸ê³  ë…¼ë¬¸**
- *High-Resolution Image Synthesis with Latent Diffusion Models* â€” Rombach et al., CVPR 2022  
- *Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding* â€” Saharia et al., NeurIPS 2022  
- *SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis* â€” Podell et al., arXiv 2023  
- *Adversarial Diffusion Distillation* â€” Sauer et al., arXiv 2023  
- *CLIPScore: A Reference-free Evaluation Metric for Image Captioning* â€” Hessel et al., arXiv 2021

---
