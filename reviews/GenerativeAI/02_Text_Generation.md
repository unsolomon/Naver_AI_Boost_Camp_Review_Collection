# ğŸ§  2ê°•: Text Generation 1 â€” LLM Pretrained Models  
> ê°•í•„ì„± êµìˆ˜ (ì„œìš¸ëŒ€í•™êµ ì‚°ì—…ê³µí•™ê³¼)  
> ì¶œì²˜: NAVER Connect Foundation ê°•ì˜ êµì¬

---

## **1. Large Language Model ê¸°ë³¸**

### ğŸ”¹ 1.1 LLM ê°œë…

**Large Language Model (LLM)**  
â†’ ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì‚¬ì „í•™ìŠµë˜ì–´, **ë²”ìš©ì ì¸ ì–¸ì–´ íƒœìŠ¤í¬ ìˆ˜í–‰ì´ ê°€ëŠ¥í•œ ëª¨ë¸**

**ì£¼ìš” íŠ¹ì§•**
- **ë²”ìš© íƒœìŠ¤í¬ ìˆ˜í–‰ ê°€ëŠ¥:** ë²ˆì—­, ìš”ì•½, QA ë“± ë‹¤ì–‘í•œ ì‘ì—… ìˆ˜í–‰  
- **ì‚¬ì „í•™ìŠµ ë°ì´í„° ê·œëª¨:** ì˜¨ë¼ì¸ì—ì„œ ìˆ˜ì§‘ ê°€ëŠ¥í•œ ìµœëŒ€ í…ìŠ¤íŠ¸ (ì˜ˆ: LLaMA í•™ìŠµ ë°ì´í„° 4TB)  
- **ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜:** 7B~65B ì´ìƒ, í•˜ë“œì›¨ì–´ í•œê³„ê¹Œì§€ í™•ì¥  
- **í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ ë‹¤ì–‘í•œ íƒœìŠ¤í¬ ìˆ˜í–‰ ê°€ëŠ¥**
- **Zero-shot / Few-shot Learning** ê°€ëŠ¥
- **Prompt ê¸°ë°˜ íƒœìŠ¤í¬ ì œì–´**  

ğŸ“˜ *ì˜ˆì‹œ ëª¨ë¸:* GPT-3.5 / GPT-4 / ChatGPT / LLaMA / Mistral / Solar ë“±  

---

### ğŸ§© Pretrained LM vs LLM

| êµ¬ë¶„ | Pretrained LM | LLM |
|------|----------------|------|
| **ì˜ˆì‹œ ëª¨ë¸** | GPT-2, BERT, T5 | GPT-3, GPT-4, LLaMA, Mistral |
| **í•™ìŠµ ë°©ì‹** | íƒœìŠ¤í¬ë³„ Finetune í•„ìš” | ì‚¬ì „í•™ìŠµ í›„ Promptë¡œ ë‹¤ì–‘í•œ íƒœìŠ¤í¬ ìˆ˜í–‰ |
| **ëª©í‘œ** | íŠ¹ì • ëª©ì ì˜ ëª¨ë¸ êµ¬ì¶• | ë²”ìš© ëª©ì  ëª¨ë¸ êµ¬ì¶• |
| **íƒœìŠ¤í¬ ìˆ˜** | 1 ëª¨ë¸ 1 íƒœìŠ¤í¬ | 1 ëª¨ë¸ ë‹¤ìˆ˜ íƒœìŠ¤í¬ ìˆ˜í–‰ ê°€ëŠ¥ |

---

### âš™ Zero-shot / Few-shot Learning

- **Zero-shot**: ì˜ˆì‹œ ì—†ì´ Promptë§Œìœ¼ë¡œ íƒœìŠ¤í¬ ìˆ˜í–‰  
- **Few-shot**: ì…ë ¥ + ì˜ˆì‹œ(ì…ë ¥/ì¶œë ¥ ìŒ, Demonstration)ë¥¼ í†µí•´ íƒœìŠ¤í¬ ìˆ˜í–‰  
- **í•µì‹¬ ì•„ì´ë””ì–´:** ëª¨ë¸ì€ Promptì— í¬í•¨ëœ ë§¥ë½ìœ¼ë¡œ ìƒˆë¡œìš´ íƒœìŠ¤í¬ë¥¼ â€œì´í•´í•˜ê³  ìˆ˜í–‰â€  

ğŸ“˜ *ì°¸ê³  ë…¼ë¬¸:* *Language Models are Few-Shot Learners (Brown et al., 2020)*

---

### ğŸ§± Prompt êµ¬ì¡°

| êµ¬ì„±ìš”ì†Œ | ì„¤ëª… |
|-----------|-------|
| **Task Description** | ìˆ˜í–‰í•  íƒœìŠ¤í¬ì— ëŒ€í•œ ì§€ì‹œë¬¸ |
| **Demonstration** | ì…ë ¥-ì¶œë ¥ ì˜ˆì‹œ (Few-shotìš©) |
| **Input** | ì‹¤ì œ ëª¨ë¸ì´ ìˆ˜í–‰í•  ì…ë ¥ ë°ì´í„° |

> ğŸ—£ï¸ ì˜ˆì‹œ  
> ```
> Task: ì•„ë˜ ì˜í™” ë¦¬ë·°ì˜ ê°ì„±ì„ ë¶„ì„í•´ì¤˜.  
> Demo: "ì§€ë£¨í•˜ì§€ ì•Šê³  í¥ë¯¸ë¡œì› ë‹¤." â†’ ê¸ì •  
> Input: "ìŠ¤í† ë¦¬ê°€ ë³„ë¡œì˜€ë‹¤."  
> Output: ë¶€ì •
> ```

---

## **1.2 Model Architecture**

LLMì€ **Transformer** ê¸°ë°˜ êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ë©°, í¬ê²Œ ë‘ ê°€ì§€ ìœ í˜•ìœ¼ë¡œ ë‚˜ë‰©ë‹ˆë‹¤.

| êµ¬ì¡° | ì„¤ëª… | ëŒ€í‘œ ëª¨ë¸ |
|------|------|------------|
| **Encoderâ€“Decoder** | ì…ë ¥ ì´í•´(Encoder) + ë¬¸ì¥ ìƒì„±(Decoder) | T5, BART |
| **Decoder-Only** | ë‹¨ì¼ ëª¨ë¸ë¡œ ì´í•´ ë° ìƒì„± ìˆ˜í–‰ | GPT ê³„ì—´, LLaMA, Mistral |

- **Encoderâ€“Decoder êµ¬ì¡°**: ì…ë ¥ê³¼ ì¶œë ¥ì„ ë¶„ë¦¬í•˜ì—¬ ì²˜ë¦¬ (ex. ë²ˆì—­ ëª¨ë¸)
- **Decoder-Only êµ¬ì¡°**: Self-Attentionê³¼ Masked Attentionìœ¼ë¡œ ìˆœì°¨ì  ìƒì„±
- **ìµœê·¼ LLMë“¤ì€ ëŒ€ë¶€ë¶„ Decoder-Only êµ¬ì¡° ì‚¬ìš©**

---

## **1.3 Pretrain Task**

ëª¨ë¸ êµ¬ì¡°ì— ë”°ë¼ ì‚¬ì „í•™ìŠµ ë°©ë²•ì´ ë‹¤ë¦…ë‹ˆë‹¤.

| êµ¬ì¡° | ì£¼ìš” í•™ìŠµ íƒœìŠ¤í¬ | ì„¤ëª… |
|------|----------------|------|
| **Encoderâ€“Decoder** | **Span Corruption** | ì…ë ¥ ë¬¸ì¥ì˜ ì¼ë¶€ë¥¼ ë§ˆìŠ¤í‚¹í•˜ê³  ë³µì› (T5ì—ì„œ ì œì•ˆ) |
| **Decoder-Only** | **Language Modeling** | ì´ì „ ë‹¨ì–´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡ (GPT-1ì—ì„œ ì œì•ˆ) |

> ëŒ€ë¶€ë¶„ì˜ ìµœì‹  LLMì€ **Causal Decoder êµ¬ì¡° + Next Token Prediction**ì„ ì‚¬ìš©í•¨  
> â‡’ ì—°ì‚° íš¨ìœ¨ì„±ê³¼ í™•ì¥ì„± ì¸¡ë©´ì—ì„œ ìœ ë¦¬

---

## **1.4 Pretrain Corpus**

**ì½”í¼ìŠ¤(Corpus)** = LLM í•™ìŠµìš© ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸ ë°ì´í„° ì§‘í•©  
(ë‰´ìŠ¤, ë¸”ë¡œê·¸, ì„œì , ìœ„í‚¤, ì»¤ë®¤ë‹ˆí‹°, ëŒ“ê¸€ ë“±)

- ë°ì´í„° í¬ê¸°: **ì•½ 5TB ì´ìƒ**
- **ì •ì œ ê³¼ì • í•„ìˆ˜**
  - ìš•ì„¤/í˜ì˜¤ í‘œí˜„ ì œê±°
  - ì¤‘ë³µ ë°ì´í„° ì œê±°
  - ê°œì¸ì •ë³´(ì´ë©”ì¼, ì „í™”ë²ˆí˜¸, ì£¼ì†Œ ë“±) í•„í„°ë§

**âš  ì£¼ì˜ì‚¬í•­**
- **Memorization**: LLMì´ í›ˆë ¨ ë°ì´í„°ì˜ íŠ¹ì • ë¬¸ì¥ì„ ì•”ê¸°í•˜ëŠ” í˜„ìƒ  
  â†’ ì¤‘ë³µëœ ë°ì´í„°ê°€ ë§ì„ìˆ˜ë¡ ì•”ê¸°ìœ¨ ì¦ê°€  
- **ê°œì¸ì •ë³´ ë…¸ì¶œ ìœ„í—˜**: í•™ìŠµ ë°ì´í„°ì— í¬í•¨ ì‹œ, ëª¨ë¸ì´ ê·¸ëŒ€ë¡œ ì¶œë ¥í•  ìˆ˜ ìˆìŒ

> ğŸ“˜ *ì°¸ê³  ì—°êµ¬:*  
> - *Quantifying Memorization Across Neural Language Models* (Carlini et al., 2023)  
> - *Whatâ€™s in My Big Data?* (Elazar et al., 2023)

---

# ğŸ§­ 2. Instruction Tuning

### ğŸ¯ ëª©ì 

LLMì´ â€œë‹¨ìˆœ í…ìŠ¤íŠ¸ ì˜ˆì¸¡â€ì„ ë„˜ì–´, **ì‚¬ëŒì˜ ì§€ì‹œë¥¼ ë”°ë¥´ëŠ” ëŠ¥ë ¥(Instruction Following)** ì„ ê°•í™”í•˜ê¸° ìœ„í•¨.

| ëª©í‘œ | ì„¤ëª… |
|------|------|
| **Safety** | ì‚¬íšŒì  í¸í–¥, í˜ì˜¤, ìœ„í—˜ ë°œì–¸ ë°©ì§€ |
| **Helpfulness** | ì‚¬ìš©ìì˜ ë‹¤ì–‘í•œ ìš”ì²­ì— ìœ ìš©í•œ ë‹µë³€ ì œê³µ |

---

### âš™ Instruction Tuning ê³¼ì • (RLHF êµ¬ì¡°)

1. **Supervised Fine-Tuning (SFT)**  
   - ë‹¤ì–‘í•œ ì‚¬ìš©ì ìš”ì²­(Prompt)ì— ëŒ€í•´ â€œì ì ˆí•œ ë‹µë³€(Demonstration)â€ì„ í•™ìŠµ  
   - ì§€ë„í•™ìŠµ ê¸°ë°˜, ì•ˆì „í•˜ê³  ìœ ìš©í•œ ë‹µë³€ ìƒì„±  

2. **Reward Modeling**  
   - LLM ìƒì„±ë¬¸ì— ëŒ€í•´ ì¸ê°„ì˜ ì„ í˜¸ë„ë¥¼ ì ìˆ˜í™”  
   - **Helpfulness/Safety** ê¸°ì¤€ìœ¼ë¡œ ë­í‚¹ í•™ìŠµ  

3. **Reinforcement Learning from Human Feedback (RLHF)**  
   - Reward Modelì˜ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµ  
   - **PPO (Proximal Policy Optimization)** ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©  

---

### ğŸ§  ì˜ˆì‹œ íë¦„

| ë‹¨ê³„ | ì…ë ¥ | ì¶œë ¥ |
|------|------|------|
| **SFT** | â€œë‹¬ ì°©ë¥™ ê³¼ì •ì„ 6ì‚´ì—ê²Œ ì„¤ëª…í•´ì¤˜â€ | â€œì‚¬ëŒë“¤ì´ ë¡œì¼“ì„ íƒ€ê³  ë‹¬ì— ê°€ëŠ” ì´ì•¼ê¸°ì•¼.â€ |
| **Reward Modeling** | ë‹µë³€ í›„ë³´ ì—¬ëŸ¬ ê°œ ìƒì„± â†’ ì¸ê°„ í‰ê°€ë¡œ ì ìˆ˜ ë§¤ê¹€ |
| **RLHF** | ë†’ì€ ì ìˆ˜ ë‹µë³€ ë°©í–¥ìœ¼ë¡œ ëª¨ë¸ ì—…ë°ì´íŠ¸ |

---

### ğŸ“ˆ íš¨ê³¼

- **Instruction Following ëŠ¥ë ¥ í–¥ìƒ**  
- **ê±°ì§“ ì •ë³´(Hallucination)** ìƒì„± ë¹ˆë„ ê°ì†Œ  
- ì‘ì€ ëª¨ë¸(1.3B)ë„ ëŒ€í˜• ëª¨ë¸(175B)ë³´ë‹¤ ë†’ì€ ì„±ëŠ¥ ê°€ëŠ¥  
- ë‹¤ì–‘í•œ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ì„±ëŠ¥ í–¥ìƒ í™•ì¸

> â€œëª¨ë¸ í¬ê¸°ë³´ë‹¤ **Instruction Tuningì˜ í’ˆì§ˆ**ì´ ë” ì¤‘ìš”í•˜ë‹¤.â€  
> â€” *Ouyang et al., 2023 (OpenAI RLHF ë…¼ë¬¸)*

---

## âœ… ê²°ë¡  ìš”ì•½

| í•­ëª© | ë‚´ìš© |
|------|------|
| **LLM ì •ì˜** | ëŒ€ê·œëª¨ ë°ì´í„°ì™€ íŒŒë¼ë¯¸í„°ë¡œ í•™ìŠµëœ ë²”ìš© ì–¸ì–´ëª¨ë¸ |
| **í•™ìŠµ íŠ¹ì§•** | Zero/Few-shot Learning ê°€ëŠ¥ |
| **Pretraining** | ëŒ€ê·œëª¨ Corpusë¡œ ì‚¬ì „í•™ìŠµ (Language Modeling ê¸°ë°˜) |
| **Instruction Tuning** | ì‚¬ëŒì˜ ì§€ì‹œë¥¼ ì˜ ë”°ë¥´ë„ë¡ ë¯¸ì„¸ ì¡°ì • (SFT + RLHF) |
| **í•µì‹¬ ê°€ì¹˜** | Safety + Helpfulness ì¤‘ì‹¬ì˜ ì¸ê°„ ì¹œí™”ì  ì–¸ì–´ëª¨ë¸ |

---

ğŸ“š **ì°¸ê³  ë¬¸í—Œ**
- Brown et al., *Language Models are Few-Shot Learners*, NeurIPS 2020  
- Raffel et al., *Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer*, 2020  
- Ouyang et al., *Training Language Models to Follow Instructions with Human Feedback*, 2023  
- Zhao et al., *A Survey of Large Language Models*, 2023  
- Solaiman & Dennison, *Process for Adapting LMs to Society (PALMS)*, NeurIPS 2021  

---
