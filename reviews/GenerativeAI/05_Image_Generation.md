# ğŸ§  5ê°•: Image Generation 1 â€” Image Generation Models Overview
> ê°•í•„ì„± êµìˆ˜ (ì„œìš¸ëŒ€í•™êµ ì‚°ì—…ê³µí•™ê³¼)  
> NAVER Connect Foundation  
> ì£¼ì œ: ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì˜ ë°œì „ â€” GAN â†’ AE â†’ Diffusion  

---

## **1ï¸âƒ£ Generative Adversarial Networks (GANs)**

### **1.1 GANs ê°œìš”**
- **êµ¬ì¡°:** Generator(ìƒì„±ì)ì™€ Discriminator(íŒë³„ì)ê°€ ê²½ìŸì ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” êµ¬ì¡°
- **ëª©í‘œ:** GeneratorëŠ” ì‹¤ì œ ë°ì´í„°ì™€ êµ¬ë¶„ ë¶ˆê°€ëŠ¥í•œ ì´ë¯¸ì§€ë¥¼ ìƒì„±,  
  DiscriminatorëŠ” ì‹¤ì œ/ê°€ì§œ ì´ë¯¸ì§€ë¥¼ íŒë³„í•˜ë„ë¡ í•™ìŠµ

**Loss Function**
\[
L_{GAN} = \min_G \max_D V(D, G) =
E_{xâˆ¼p_{data}(x)}[log D(x)] + E_{zâˆ¼p_z(z)}[log(1âˆ’D(G(z)))]
\]

> ì¶œì²˜: *Goodfellow et al., NeurIPS 2014*

#### âš ï¸ í•œê³„ì 
- í•™ìŠµ ë¶ˆì•ˆì • (Mode collapse, Gradient vanishing)
- Generator/Discriminator ê°„ í•™ìŠµ ë¶ˆê· í˜•
- ê³ í•´ìƒë„ ì´ë¯¸ì§€ ìƒì„±ì˜ ì–´ë ¤ì›€

---

## **2ï¸âƒ£ Conditional GANs (cGAN, Pix2Pix)**

### **2.1 Conditional GAN**
- ì…ë ¥ì— **ì¡°ê±´(condition)** ì„ ì¶”ê°€í•˜ì—¬ íŠ¹ì • ì†ì„±ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±
- ì˜ˆ: â€œê°œâ€ â†’ â€œê°œ ì–¼êµ´ ìƒì„±â€  
  â€œë°¤ ì‚¬ì§„â€ â†’ â€œë‚®ìœ¼ë¡œ ë³€í™˜â€

**Loss Function**
\[
L_{cGAN} = E_{xâˆ¼p_{data}}[log D(x|y)] + E_{zâˆ¼p_z}[log(1âˆ’D(G(z|y)))]
\]

> *Mirza & Osindero, 2014*

---

### **2.2 Pix2Pix (Image-to-Image Translation)**
- ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì¡°ê±´ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬ ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” êµ¬ì¡°  
- **Paired Data í•„ìš”**
  - ì˜ˆ: í‘ë°± â†” ì»¬ëŸ¬ ì´ë¯¸ì§€ ë³€í™˜
- GeneratorëŠ” U-Net êµ¬ì¡°, DiscriminatorëŠ” PatchGAN í™œìš©

> *Isola et al., CVPR 2017*

---

## **3ï¸âƒ£ CycleGAN & StarGAN**

### **3.1 CycleGAN**
- **Unpaired Data** ë¡œë„ ì´ë¯¸ì§€ ë³€í™˜ ê°€ëŠ¥
- í•µì‹¬: **Cycle Consistency Loss**

**Loss Function**
\[
L(G,F,D_X,D_Y) = L_{GAN}(G,D_Y,X,Y) + L_{GAN}(F,D_X,Y,X) + Î»L_{cyc}(G,F)
\]
\[
L_{cyc}(G,F) = E_{xâˆ¼p(x)}[||F(G(x))âˆ’x||_1] + E_{yâˆ¼p(y)}[||G(F(y))âˆ’y||_1]
\]

> *Zhu et al., ICCV 2017*

ğŸ“Œ **íŠ¹ì§•**
- Label ì—†ëŠ” ì´ë¯¸ì§€ ë³€í™˜ ê°€ëŠ¥ (ì˜ˆ: ì—¬ë¦„ â†” ê²¨ìš¸, ë§ â†” ì–¼ë£©ë§)
- Cycle Lossë¡œ ì›ë³¸ ë³µì› ë³´ì¥

---

### **3.2 StarGAN**
- ì—¬ëŸ¬ ë„ë©”ì¸ ë³€í™˜ì„ **í•˜ë‚˜ì˜ ëª¨ë¸**ë¡œ ìˆ˜í–‰ ê°€ëŠ¥
- CycleGANì˜ í™•ì¥íŒ  
- ê° ë„ë©”ì¸ì— ëŒ€í•œ **ë„ë©”ì¸ ë ˆì´ë¸”(c)** ì„ ì¶”ê°€í•˜ì—¬ ë‹¤ì¤‘ ë³€í™˜ ìˆ˜í–‰

**Loss Function**
\[
L_G = L_{GAN} + Î»_{cls}L_{cls}^f + Î»_{rec}L_{rec}
\]
- \( L_{GAN} \): Adversarial Loss  
- \( L_{cls} \): ë„ë©”ì¸ ë¶„ë¥˜ Loss  
- \( L_{rec} \): Cycle Consistency Loss

> *Choi et al., CVPR 2018*

---

## **4ï¸âƒ£ ProgressiveGAN & StyleGAN**

### **4.1 ProgressiveGAN**
- ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´  
  ì €í•´ìƒë„ â†’ ì ì§„ì (Progressive)ìœ¼ë¡œ í•´ìƒë„ë¥¼ ë†’ì´ëŠ” êµ¬ì¡°
- ê° ë‹¨ê³„ë§ˆë‹¤ ê¸°ì¡´ ì´ë¯¸ì§€ë¥¼ **weighted sum**ìœ¼ë¡œ ê²°í•©í•˜ì—¬ ì•ˆì •ì ìœ¼ë¡œ í•™ìŠµ

> *Karras et al., ICLR 2018*

---

### **4.2 StyleGAN**
- ProgressiveGANì— **Style Injection** ê°œë… ì¶”ê°€  
- ì ì¬ ê³µê°„ \(Z\) â†’ Mapping Network \(f\) â†’ Style ê³µê°„ \(W\) ë³€í™˜

**í•µì‹¬ êµ¬ì¡°**
- Adaptive Instance Normalization (AdaIN):
  \[
  AdaIN(x_i, y) = y_{s,i} \frac{x_i - Î¼(x_i)}{Ïƒ(x_i)} + y_{b,i}
  \]

- Styleë³„ë¡œ coarse~fine ìˆ˜ì¤€ì˜ ì‹œê°ì  ìš”ì†Œ ì œì–´ ê°€ëŠ¥  
- ì‹¤ì œ ì¸ë¬¼ ìˆ˜ì¤€ì˜ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„±

> *Karras et al., CVPR 2019*

---

## **5ï¸âƒ£ Autoencoders (AEs)**

### **5.1 ê¸°ë³¸ Autoencoder**
- Encoder(ì…ë ¥ ì••ì¶•) + Decoder(ë³µì›) êµ¬ì¡°
- Reconstruction Loss (MSE or MAE) ì‚¬ìš©

\[
L_{AE}(Î¸, Ï†) = \frac{1}{n} Î£ ||x_i - f_Î¸(g_Ï†(x_i))||^2
\]

> *Rumelhart et al., 1986*

---

### **5.2 Variational Autoencoder (VAE)**
- ì ì¬ ê³µê°„ì„ **í™•ë¥  ë¶„í¬**ë¡œ ê°€ì •
- KL Divergence ì¶”ê°€í•˜ì—¬ ì •ê·œ ë¶„í¬ì— ë§ê²Œ ì œì•½

\[
L_{VAE}(Î¸, Ï†) = E_{zâˆ¼q_Ï†(z|x)}[log p_Î¸(x|z)] - D_{KL}(q_Ï†(z|x) || p(z))
\]

> *Kingma & Welling, ICLR 2014*

ğŸ“Œ **ì¥ì **
- ì ì¬ ê³µê°„ì˜ êµ¬ì¡°ì  ì˜ë¯¸ í•™ìŠµ  
- ë‹¤ì–‘í•œ ìƒ˜í”Œ ìƒì„± ê°€ëŠ¥ (ì—°ì†ì„± ë³´ì¥)

---

### **5.3 Vector Quantized VAE (VQ-VAE)**
- **ì´ì‚°ì  ì ì¬ ê³µê°„(discrete latent space)** ì‚¬ìš©  
- Codebook(embedding dictionary) ê¸°ë°˜ìœ¼ë¡œ ì–‘ìí™” ìˆ˜í–‰

\[
L_{VQ-VAE} = log p(x|z_q) + ||sg[z_e] - e||^2 + Î²||z_e - sg[e]||^2
\]

> *Van Den Oord & Vinyals, NeurIPS 2017*

ğŸ“Œ **í™œìš©**
- í…ìŠ¤íŠ¸, ìŒì„±, ì´ë¯¸ì§€ ëª¨ë‘ ì ìš© ê°€ëŠ¥  
- Diffusion ëª¨ë¸ì˜ ê¸°ë³¸ êµ¬ì¡°ë¡œ ì‚¬ìš©ë¨

---

## **6ï¸âƒ£ Diffusion Models**

> 2020ë…„ ì´í›„ ì´ë¯¸ì§€ ìƒì„± ë¶„ì•¼ì˜ **íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜**

### **6.1 DDPM (Denoising Diffusion Probabilistic Models)**
- ì´ë¯¸ì§€ì— ì ì§„ì ìœ¼ë¡œ **ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¶”ê°€ (Forward Process)**  
- Reverse Processì—ì„œ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ë©° ì´ë¯¸ì§€ ë³µì›  
- í™•ë¥ ì  ëª¨ë¸ë§ ê¸°ë°˜, ë§¤ìš° ë†’ì€ í€„ë¦¬í‹°ì˜ ì´ë¯¸ì§€ ìƒì„± ê°€ëŠ¥

> *Ho et al., NeurIPS 2020*

---

### **6.2 DDIM (Denoising Diffusion Implicit Models)**
- DDPMì˜ **deterministic sampling** ë²„ì „  
- ì „ì²´ stepì„ ê±°ì¹˜ì§€ ì•Šì•„ë„ ê³ í’ˆì§ˆ ìƒì„± ê°€ëŠ¥  
- **Non-Markovian Diffusion** ì‚¬ìš©

> *Song et al., ICLR 2021*

---

### **6.3 CFG (Classifier & Classifier-Free Guidance)**

#### (1) Classifier Guidance
- Diffusion ê³¼ì • ì¤‘, íŠ¹ì • classë¡œ ê°€ì´ë“œë¥¼ ì£¼ê¸° ìœ„í•´  
  **í•™ìŠµëœ classifierì˜ gradient**ë¥¼ í™œìš©
\[
âˆ‡_x log p(x_t|y) = âˆ‡_x log p_Î¸(x_t) + Î³âˆ‡_x log p_Ï†(y|x_t)
\]
> *Dhariwal & Nichol, NeurIPS 2021*

#### (2) Classifier-Free Guidance
- ë³„ë„ classifier ì—†ì´,  
  conditional / unconditional scoreë¥¼ í˜¼í•©í•˜ì—¬ ì œì–´
\[
âˆ‡_x log p(x_t|y) = Î³âˆ‡_x log p_Î¸(x_t|y) + (1âˆ’Î³)âˆ‡_x log p_Î¸(x_t)
\]
> *Ho & Salimans, arXiv 2022*

ğŸ“Œ **ì¥ì **
- ì¶”ê°€ ëª¨ë¸ ì—†ì´ condition ë°˜ì˜ ê°€ëŠ¥  
- Guidance scale ì¡°ì ˆë¡œ ìƒì„± ì œì–´ ìš©ì´

---

### **6.4 LDM (Latent Diffusion Models)**
- ì´ë¯¸ì§€ ëŒ€ì‹  **ì €ì°¨ì› ì ì¬ ê³µê°„(latent space)** ì—ì„œ Diffusion ìˆ˜í–‰  
- ê³ í•´ìƒë„ ì´ë¯¸ì§€ í•™ìŠµ ë¹„ìš© ì ˆê°  
- Cross-Attentionìœ¼ë¡œ Text, Layout ë“± condition ë°˜ì˜

> *Rombach et al., CVPR 2022*

ğŸ“Œ **ì‘ìš© ë¶„ì•¼**
- Text-to-Image (Stable Diffusion)  
- Inpainting (ê²°ì† ì˜ì—­ ë³µì›)  
- Super-Resolution (ì €í•´ìƒë„ â†’ ê³ í•´ìƒë„)

---

## âœ… **ìš”ì•½ ì •ë¦¬**

| êµ¬ë¶„ | ì£¼ìš” ëª¨ë¸ | í•µì‹¬ ì•„ì´ë””ì–´ | ëŒ€í‘œ ë…¼ë¬¸ |
|------|-------------|----------------|-------------|
| **GANs** | GAN, cGAN, CycleGAN, StarGAN | Adversarial Learning | Goodfellow et al. (2014) |
| **Autoencoder ê³„ì—´** | AE, VAE, VQ-VAE | Encoding & Reconstruction | Kingma & Welling (2014) |
| **Diffusion ê³„ì—´** | DDPM, DDIM, CFG, LDM | í™•ë¥ ì  ë…¸ì´ì¦ˆ ì œê±° ê¸°ë°˜ ìƒì„± | Ho et al. (2020), Rombach et al. (2022) |

---

ğŸ“š **ì°¸ê³  ë¬¸í—Œ**
- Goodfellow et al., *Generative Adversarial Nets*, NeurIPS 2014  
- Isola et al., *Pix2Pix*, CVPR 2017  
- Zhu et al., *CycleGAN*, ICCV 2017  
- Choi et al., *StarGAN*, CVPR 2018  
- Karras et al., *ProgressiveGAN / StyleGAN*, ICLRÂ·CVPR 2018â€“2019  
- Kingma & Welling, *VAE*, ICLR 2014  
- Van Den Oord et al., *VQ-VAE*, NeurIPS 2017  
- Ho et al., *DDPM*, NeurIPS 2020  
- Song et al., *DDIM*, ICLR 2021  
- Rombach et al., *LDM (Stable Diffusion)*, CVPR 2022  

---
