# ğŸ“˜ N2M ìì—°ì–´ ë¬¸ì œ ëª¨ë¸ë§ ë° ë¶„ì„ (ì´ë¡ )

## í•µì‹¬ ìš”ì•½

-   **N2M ë¬¸ì œ**: Nê°œì˜ ì…ë ¥ â†’ Mê°œì˜ ì¶œë ¥
-   **ëª¨ë¸ êµ¬ì¡°**: Encoder-Decoder / Decoder-Only
-   **Search Strategy**: Greedy, Beam, Top-K, Top-P, Temperature
-   **Loss**: Cross Entropy Loss
-   **í‰ê°€**: ROUGE, BLEU

------------------------------------------------------------------------


## 1. N2M ë¬¸ì œ ì •ì˜

-   **Nê°œì˜ ì…ë ¥ â†’ Mê°œì˜ ì¶œë ¥**
-   ì£¼ìš” ì˜ˆì‹œ:
    -   ì–¸ì–´ ëª¨ë¸ (Language Modeling)
    -   í…ìŠ¤íŠ¸ ìš”ì•½ (Summarization)
    -   ë²ˆì—­ (Translation)
    -   ì§ˆì˜ì‘ë‹µ (Question Answering)

### Text Summarization ìœ í˜•

-   **Extractive Summarization**: ì›ë¬¸ì—ì„œ ì¤‘ìš” ë¬¸ì¥ë§Œ ì¶”ì¶œ
-   **Abstractive Summarization**: ìƒˆë¡œìš´ ë¬¸ì¥ ìƒì„± (ìƒì„±í˜• ìš”ì•½)

------------------------------------------------------------------------

## 2. ì•„í‚¤í…ì²˜ ìœ í˜•

### 2.1 Seq2Seq ëª¨ë¸

-   **RNN ê¸°ë°˜ Encoder-Decoder êµ¬ì¡°**
    -   ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ì¸ì½”ë”© í›„ ë””ì½”ë”©
-   **Decoder-Only êµ¬ì¡°**
    -   ì¸ì½”ë” ì—†ì´ ê³¼ê±° í† í°ë§Œ í™œìš©í•´ ë‹¤ìŒ í† í° ì˜ˆì¸¡

### 2.2 Transformer ëª¨ë¸

-   **Encoder-Decoder êµ¬ì¡°**
    -   ëŒ€í‘œ: BART, T5
    -   ì…ë ¥ ì „ì²´ë¥¼ ì¸ì½”ë”© í›„ ë””ì½”ë”ì—ì„œ ìƒì„±
-   **Decoder-Only êµ¬ì¡°**
    -   ëŒ€í‘œ: GPT ì‹œë¦¬ì¦ˆ
    -   ì´ì „ ì¶œë ¥ í† í°ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ìˆœì°¨ì  ìƒì„±

### 2.3 Search Strategy (ìƒì„± ë°©ì‹)

-   **Deterministic Search (ê²°ì •ì  íƒìƒ‰)**
    -   Greedy Search
    -   Beam Search
-   **Random Sampling (í™•ë¥ ì  íƒìƒ‰)**
    -   Top-K Sampling
    -   Top-P (Nucleus) Sampling
-   **Temperature ì¡°ì ˆ**: í™•ë¥  ë¶„í¬ì˜ ë‹¤ì–‘ì„±/ì§‘ì¤‘ë„ë¥¼ ì œì–´

------------------------------------------------------------------------

## 3. Loss Function

-   **Cross Entropy Loss**
    -   ê° í† í°ì˜ ì˜ˆì¸¡ í™•ë¥ ê³¼ ì‹¤ì œ ì •ë‹µ ê°„ì˜ ì°¨ì´ ê³„ì‚°
    -   ìƒì„± ëª¨ë¸ í•™ìŠµì˜ ê¸°ë³¸ Loss

------------------------------------------------------------------------

## 4. í‰ê°€ ì§€í‘œ

### 4.1 ROUGE (Recall-Oriented Understudy for Gisting Evaluation)

-   **N-gram Recall ê¸°ë°˜**
-   ì£¼ìš” ì§€í‘œ:
    -   ROUGE-N: N-gram ë‹¨ìœ„ ë¹„êµ
    -   ROUGE-L: Longest Common Subsequence

### 4.2 BLEU (BiLingual Evaluation Understudy)

-   **N-gram Precision ê¸°ë°˜**
-   ì •ë°€ë„ë¥¼ ê¸°í•˜í‰ê· ìœ¼ë¡œ ê³„ì‚°
-   ë²ˆì—­ ë° ìƒì„± í’ˆì§ˆ í‰ê°€ì— ë„ë¦¬ ì‚¬ìš©

### 4.3 Reported SOTA ì„±ëŠ¥ (ì˜ˆì‹œ)

-   CNN/Daily Mail: Pegasus â†’ ROUGE-L ì•½ 44
-   XSum: Pegasus â†’ ROUGE-L ì•½ 47
-   WMT'14 ë²ˆì—­: BiBERT â†’ BLEU 30+

------------------------------------------------------------------------


