## âœ… Extraction-based MRC í•µì‹¬ ìš”ì•½

| êµ¬ë¶„                  | ì„¤ëª…                                                          |
| ------------------- | ----------------------------------------------------------- |
| **ì •ì˜**              | ì§ˆë¬¸ì˜ ë‹µì´ ì§€ë¬¸ ë‚´ íŠ¹ì • spanì— ì¡´ì¬                                     |
| **ëŒ€í‘œ ë°ì´í„°ì…‹**         | SQuAD, KorQuAD, NewsQA, Natural Questions                   |
| **í‰ê°€ ë°©ë²•**           | EM / F1 Score                                               |
| **ì „ì²˜ë¦¬**             | Tokenization, Special Tokens, Attention Mask, Token Type ID |
| **í•™ìŠµ(Fine-tuning)** | Start / End ìœ„ì¹˜ ì˜ˆì¸¡ (Token Classification)                    |
| **í›„ì²˜ë¦¬**             | ë¶ˆê°€ëŠ¥í•œ ì¡°í•© ì œê±°, score í•©ì‚°ìœ¼ë¡œ ìµœì  ë‹µ ì„ íƒ                              |

---

## 1. Extraction-based MRC

### ğŸ§  ë¬¸ì œ ì •ì˜

> ì§ˆë¬¸(question)ì˜ ë‹µë³€(answer)ì´ í•­ìƒ ì£¼ì–´ì§„ ì§€ë¬¸(context) ë‚´ì— **ì—°ì†ëœ span(í† í°ì˜ êµ¬ê°„)**ìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” í˜•íƒœì˜ MRC ë¬¸ì œ.

ì¦‰, ëª¨ë¸ì€ **ë¬¸ì„œì—ì„œ ì •ë‹µì´ ìœ„ì¹˜í•œ êµ¬ê°„ì˜ ì‹œì‘(start)ê³¼ ë(end)ì„ ì˜ˆì¸¡**í•œë‹¤.

**ëŒ€í‘œ ë°ì´í„°ì…‹**

* SQuAD
* KorQuAD
* NewsQA
* Natural Questions

ì´ëŸ¬í•œ ë°ì´í„°ì…‹ë“¤ì€ ëª¨ë‘ **Hugging Face Datasets** ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë‹¤.
ğŸ”— [https://huggingface.co/datasets](https://huggingface.co/datasets)

---

### âš™ï¸ í‰ê°€ ë°©ë²• (Evaluation Metrics)

#### ğŸŸ© Exact Match (EM)

* ì˜ˆì¸¡ê°’ì´ ì •ë‹µê³¼ **ë¬¸ì(character) ë‹¨ìœ„ë¡œ ì™„ì „íˆ ì¼ì¹˜í•  ë•Œë§Œ 1ì ** ë¶€ì—¬.
* í•˜ë‚˜ë¼ë„ ë‹¤ë¥´ë©´ 0ì  ì²˜ë¦¬.

#### ğŸŸ¨ F1 Score

* **ì˜ˆì¸¡ê°’ê³¼ ì •ë‹µì˜ í† í° ë‹¨ìœ„ overlap ë¹„ìœ¨**ì„ ê¸°ì¤€ìœ¼ë¡œ 0~1 ì‚¬ì´ì˜ ì ìˆ˜ë¥¼ ë¶€ì—¬.

| í•­ëª©            | ê³„ì‚°ì‹                   | ì˜ˆì‹œ                |
| ------------- | --------------------- | ----------------- |
| **Precision** | TP / (TP + FP)        | 1 / (1 + 0) = 1   |
| **Recall**    | TP / (TP + FN)        | 1 / (1 + 1) = 0.5 |
| **F1**        | 2 Ã— (P Ã— R) / (P + R) | â‰ˆ 0.67            |

**ì˜ˆì‹œ 2**

* Precision = 2/3 â‰ˆ 0.67
* Recall = 2/2 = 1
* F1 = 2Ã—(0.67Ã—1)/(0.67+1) = 0.8

ğŸ§© **í•´ì„**

* **Precision(ì •ë°€ë„)**: ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ì¤‘ ì‹¤ì œ ì •ë‹µ ë¹„ìœ¨ (False Positive ìµœì†Œí™”)
* **Recall(ì¬í˜„ìœ¨)**: ì‹¤ì œ ì •ë‹µ ì¤‘ ëª¨ë¸ì´ ë§íŒ ë¹„ìœ¨ (False Negative ìµœì†Œí™”)
* **F1 Score**: Precisionê³¼ Recallì˜ ê· í˜•ì„ ë‚˜íƒ€ëƒ„.
  â†’ **ë°ì´í„° ë¶ˆê· í˜• í™˜ê²½ì—ì„œ íŠ¹íˆ ìœ ìš©**

---

### ğŸ” Overview

Extraction-based MRCì˜ ì „ë°˜ì ì¸ íŒŒì´í”„ë¼ì¸:

1. **Pre-processing (ì „ì²˜ë¦¬)**

   * í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•˜ê³  ëª¨ë¸ ì…ë ¥ìœ¼ë¡œ ë³€í™˜
2. **Fine-tuning (ë¯¸ì„¸ì¡°ì •)**

   * Pre-trained ëª¨ë¸(BERT ë“±)ì„ MRC ë°ì´í„°ì…‹ì— ë§ê²Œ í•™ìŠµ
3. **Post-processing (í›„ì²˜ë¦¬)**

   * start/end ìœ„ì¹˜ ì˜ˆì¸¡ ê²°ê³¼ì—ì„œ ìµœì ì˜ ì •ë‹µì„ ì¶”ì¶œ

---

## 2. Pre-processing (ì „ì²˜ë¦¬)

ì „ì²˜ë¦¬ ê³¼ì •ì€ **í…ìŠ¤íŠ¸ë¥¼ í† í° ë‹¨ìœ„ë¡œ ë¶„í•´í•˜ê³ **,
ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ì…ë ¥ í˜•íƒœë¡œ ë§Œë“œëŠ” ê³¼ì •ì´ë‹¤.

---

### ğŸ§© Tokenization

> í…ìŠ¤íŠ¸ë¥¼ ì‘ì€ ë‹¨ìœ„(Token)ë¡œ ë‚˜ëˆ„ëŠ” ê³¼ì •

* ê¸°ì¤€: ë„ì–´ì“°ê¸°, í˜•íƒœì†Œ, subword ë“± ë‹¤ì–‘í•¨
* ìµœê·¼ì—ëŠ” **BPE(Byte Pair Encoding)** ê¸°ë°˜ í† í¬ë‚˜ì´ì € ì‚¬ìš©
* ë³¸ ê°•ì˜ì—ì„œëŠ” **WordPiece Tokenizer** ì‚¬ìš©

#### ì˜ˆì‹œ

â€œë¯¸êµ­êµ°ëŒ€ë‚´ë‘ë²ˆì§¸ë¡œë†’ì€ì§ìœ„ëŠ”ë¬´ì—‡ì¸ê°€?â€
â†’ `[â€˜ë¯¸êµ­â€™, â€˜êµ°ëŒ€â€™, â€˜ë‚´â€™, â€˜ë‘ë²ˆì§¸â€™, â€˜##ë¡œâ€™, â€˜ë†’ì€â€™, â€˜ì§â€™, â€˜##ìœ„ëŠ”â€™, â€˜ë¬´ì—‡ì¸ê°€â€™, â€˜?â€™]`

---

### ğŸ”– Special Tokens

* `[CLS]`ë¡œ ë¬¸ì¥ ì‹œì‘
* `[SEP]`ìœ¼ë¡œ **Questionê³¼ Contextë¥¼ êµ¬ë¶„**

```
[CLS] Question [SEP] Context [SEP]
```

---

### ğŸ§  Attention Mask

* ëª¨ë¸ì´ **ì–´ë–¤ í† í°ì— ì£¼ì˜(attention)**ë¥¼ ê¸°ìš¸ì¼ì§€ ê²°ì •
* 0 â†’ ë¬´ì‹œ, 1 â†’ ì—°ì‚° í¬í•¨
* ì£¼ë¡œ `[PAD]` ê°™ì€ ì˜ë¯¸ ì—†ëŠ” í† í°ì„ ë¬´ì‹œí•˜ê¸° ìœ„í•´ ì‚¬ìš©

---

### ğŸ§© Token Type IDs

* ì…ë ¥ì´ 2ê°œ ì´ìƒì˜ ì‹œí€€ìŠ¤ë¡œ êµ¬ì„±ë  ë•Œ(ì˜ˆ: ì§ˆë¬¸ + ì§€ë¬¸)
* ê° ì‹œí€€ìŠ¤ì— **ID(0,1)**ë¥¼ ë¶€ì—¬í•˜ì—¬ ëª¨ë¸ì´ êµ¬ë¶„ ê°€ëŠ¥í•˜ë„ë¡ í•¨

---

### ğŸ§¾ ëª¨ë¸ ì¶œë ¥ê°’

* ì •ë‹µì€ **ë¬¸ì„œ ë‚´ ì—°ì†ëœ span(í† í° êµ¬ê°„)**
* ë”°ë¼ì„œ ì •ë‹µì„ ìƒì„±í•˜ì§€ ì•Šê³ ,
  **â€œì‹œì‘ ìœ„ì¹˜(start)â€ì™€ â€œë ìœ„ì¹˜(end)â€ë¥¼ ì˜ˆì¸¡**í•˜ëŠ” **Token Classification ë¬¸ì œ**ë¡œ ë³€í™˜.

ì¦‰, ëª¨ë¸ì€ ë‹¤ìŒ ë‘ í™•ë¥  ë¶„í¬ë¥¼ í•™ìŠµí•œë‹¤:

* Start logits
* End logits

---

## 3. Fine-tuning (ë¯¸ì„¸ì¡°ì •)

### âš™ï¸ ê³¼ì • ìš”ì•½

1. **Pre-trained Language Model (e.g., BERT)** ìœ„ì—
   **start/end ìœ„ì¹˜ ì˜ˆì¸¡ìš© Linear Classifier**ë¥¼ ì¶”ê°€í•œë‹¤.
2. ê° í† í°ì˜ ì„ë² ë”©ì„ ì…ë ¥ë°›ì•„

   * Start ìœ„ì¹˜ í™•ë¥  ë¶„í¬
   * End ìœ„ì¹˜ í™•ë¥  ë¶„í¬
     ë¥¼ ì¶œë ¥í•œë‹¤.
3. **Cross Entropy Loss**ë¡œ í•™ìŠµ.

### ğŸ” ëª©ì 

> ì…ë ¥ëœ ë¬¸ì¥(context + question)ì—ì„œ ì •ë‹µ spanì„ ì°¾ë„ë¡ ëª¨ë¸ì„ ìµœì í™”

---

## 4. Post-processing (í›„ì²˜ë¦¬)

### ğŸš« ë¶ˆê°€ëŠ¥í•œ ë‹µ ì œê±°í•˜ê¸°

ë‹¤ìŒê³¼ ê°™ì€ ê²½ìš° í›„ë³´(candidates)ì—ì„œ ì œì™¸í•œë‹¤.

* End positionì´ start positionë³´ë‹¤ ì•ì„  ê²½ìš°
  (ì˜ˆ: start=90, end=80)
* ì˜ˆì¸¡ ìœ„ì¹˜ê°€ context ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ê²½ìš°
  (ì˜ˆ: ì§ˆë¬¸ ì˜ì—­ì— ë‹µì´ ì¡´ì¬)
* `max_answer_length`ë³´ë‹¤ ê¸´ ê²½ìš°

---

### ğŸ† ìµœì ì˜ ë‹µì•ˆ ì°¾ê¸°

1. Start / End logitsì—ì„œ **scoreê°€ ë†’ì€ Nê°œ í›„ë³´**ë¥¼ ê°ê° ì„ íƒ
2. ë¶ˆê°€ëŠ¥í•œ start-end ì¡°í•© ì œê±°
3. ê°€ëŠ¥í•œ ì¡°í•©ë“¤ì„ **score í•©ì´ í° ìˆœì„œë¡œ ì •ë ¬**
4. ìµœê³  ì ìˆ˜ ì¡°í•©ì„ ìµœì¢… ì •ë‹µìœ¼ë¡œ ì„ ì •
5. `Top-k`ë¥¼ ì¶œë ¥í•  ë•ŒëŠ” ìƒìœ„ kê°œì˜ ì¡°í•©ì„ ë°˜í™˜

---



ğŸ“š **ì°¸ê³ ë¬¸í—Œ ë° ì¶œì²˜**

* Rajpurkar et al., *SQuAD: 100,000+ Questions for Machine Comprehension of Text*
* Devlin et al., *BERT: Pre-training of Deep Bidirectional Transformers* (NAACL 2019)
* [https://huggingface.co/datasets/rajpurkar/squad](https://huggingface.co/datasets/rajpurkar/squad)
* [http://jalammar.github.io/illustrated-bert](http://jalammar.github.io/illustrated-bert)
* [https://huggingface.co/datasets](https://huggingface.co/datasets)
