# ğŸ“š Passage Retrieval â€“ Sparse Embedding

> **Lecture 4. Passage Retrieval: Sparse Embedding**
> Instructor: Minjoon Seo, KAIST AI ëŒ€í•™ì›
> â“’ NAVER Connect Foundation

---
## âœ… ì •ë¦¬ ìš”ì•½

| êµ¬ë¶„                    | í•µì‹¬ ë‚´ìš©                           |
| --------------------- | ------------------------------- |
| **Passage Retrieval** | Queryì™€ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ì°¾ëŠ” ê³¼ì •         |
| **Sparse Embedding**  | ë‹¨ì–´ ë“±ì¥ ì—¬ë¶€ ê¸°ë°˜ ë²¡í„° í‘œí˜„ (BoW, TF-IDF) |
| **TF-IDF**            | ë‹¨ì–´ ì¤‘ìš”ë„ = ë¹ˆë„(TF) Ã— í¬ê·€ë„(IDF)      |
| **ì¥ì **                | êµ¬í˜„ ë‹¨ìˆœ, íš¨ìœ¨ì , ê³ í•´ìƒë„ ë‹¨ì–´ ë¹„êµ          |
| **ë‹¨ì **                | ë‹¨ì–´ ì˜ë¯¸ ë°˜ì˜ ë¶ˆê°€ (ë™ì˜ì–´, ë¬¸ë§¥ ë¬´ì‹œ)        |
| **BM25**              | TF-IDF ê°œì„  ë²„ì „ (ë¬¸ì„œ ê¸¸ì´Â·í¬í™” ë³´ì •)      |

---

## 1ï¸âƒ£ Introduction to Passage Retrieval

### ğŸ§  ê°œë… ì •ì˜

**Passage Retrieval**

> ì£¼ì–´ì§„ **ì§ˆë¬¸(Query)** ì— ëŒ€í•´ **ê°€ì¥ ê´€ë ¨ ìˆëŠ” ë¬¸ì„œ(Passage)** ë¥¼ ì°¾ì•„ë‚´ëŠ” ê³¼ì •.

ì´ëŠ” ì˜¤í”ˆ ë„ë©”ì¸ ì§ˆì˜ì‘ë‹µ(ODQA, *Open-Domain Question Answering*)ì˜ ì²« ë‹¨ê³„ë¡œ,
ìˆ˜ë§ì€ ë¬¸ì„œ ì¤‘ **ì§ˆë¬¸ê³¼ ì—°ê´€ëœ í›„ë³´ ë¬¸ì„œ**ë¥¼ ë¹ ë¥´ê³  ì •í™•íˆ ê²€ìƒ‰í•´ì•¼ í•œë‹¤.

---

### ğŸ§© Passage Retrieval with MRC

MRC(Task)ì™€ ê²°í•©í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ 2ë‹¨ê³„ êµ¬ì¡°ë¡œ êµ¬ì„±ëœë‹¤.

1. **Stage 1 â€“ Passage Retrieval:**

   * ëŒ€ê·œëª¨ ë¬¸ì„œ ì§‘í•©ì—ì„œ ì§ˆë¬¸ì— ë§ëŠ” ë¬¸ì„œ í›„ë³´ë¥¼ ì°¾ìŒ
2. **Stage 2 â€“ Machine Reading Comprehension:**

   * Retrievalë¡œ ì°¾ì€ ë¬¸ì„œ ë‚´ì—ì„œ **ì •ë‹µì„ ì¶”ì¶œ ë˜ëŠ” ìƒì„±**

> ğŸ’¡ *ì¦‰,*
> Passage Retrievalì€ MRCì˜ â€œì…ë ¥ ì •ì œ ë‹¨ê³„â€ë¡œ,
> ëª¨ë¸ì´ ë‹µë³€í•  ë¬¸ë§¥(Context)ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì¢í˜€ì£¼ëŠ” ì—­í• ì„ í•œë‹¤.

---

### ğŸ” Retrieval ê³¼ì • ê°œìš”

1. Queryì™€ ê° Passageë¥¼ **ë²¡í„°(embedding)** ë¡œ ë³€í™˜
2. ë‘ ì„ë² ë”© ê°„ **ìœ ì‚¬ë„(similarity)** ê³„ì‚°
3. ê°€ì¥ ìœ ì‚¬ë„ê°€ ë†’ì€ ë¬¸ì„œë¥¼ ì„ íƒ (Top-k ranking)

> ì˜ˆì‹œ:
> `ì§ˆë¬¸: "BTSì˜ ë¦¬ë”ëŠ” ëˆ„êµ¬ì¸ê°€?"`
> â†’ ë¬¸ì„œ ì„ë² ë”© ì¤‘ â€œBTSâ€, â€œRMâ€, â€œë¦¬ë”â€ì™€ ì—°ê´€ ë†’ì€ Passage ì„ íƒ

---

## 2ï¸âƒ£ Passage Embedding & Sparse Embedding

Passage Retrievalì˜ í•µì‹¬ì€ **ë¬¸ì„œ ì„ë² ë”©(Embedding)** ë°©ë²•ì´ë‹¤.

---

### ğŸ“˜ Passage Embedding

> í…ìŠ¤íŠ¸(ë¬¸ì„œ, ë¬¸ì¥)ë¥¼ ë²¡í„°ë¡œ í‘œí˜„í•˜ëŠ” ë°©ë²•.

ì´ ë²¡í„° ê³µê°„ì—ì„œ **Queryâ€“Passage ê°„ì˜ ê±°ë¦¬(distance)** í˜¹ì€ **ìœ ì‚¬ë„(similarity)** ë¥¼ ê³„ì‚°í•˜ì—¬
ê²€ìƒ‰ ëŒ€ìƒ ë¬¸ì„œì˜ ê´€ë ¨ë„ë¥¼ í‰ê°€í•œë‹¤.

**ì£¼ìš” ë°©ë²•**

* Sparse Embedding (í¬ì†Œ ë²¡í„° í‘œí˜„)
* Dense Embedding (ë°€ì§‘ ë²¡í„° í‘œí˜„, e.g. DPR, ColBERT ë“±)

ì´ë²ˆ ê°•ì˜ì—ì„œëŠ” **Sparse Embedding**ì— ì´ˆì ì„ ë§ì¶˜ë‹¤.

---

### ğŸŒ¿ Sparse Embedding ì†Œê°œ

> ë¬¸ì„œ ë‚´ ë‹¨ì–´ë¥¼ **0ê³¼ 1**, í˜¹ì€ **ë¹ˆë„ìˆ˜ ê¸°ë°˜ ê°’**ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ê³ ì°¨ì› ë²¡í„° ë°©ì‹.

ì¦‰, ê° ë‹¨ì–´ê°€ ë²¡í„° ê³µê°„ì˜ ì°¨ì›ì„ êµ¬ì„±í•œë‹¤.
ë¬¸ì„œê°€ í¬í•¨í•˜ëŠ” ë‹¨ì–´ì— ë”°ë¼ **ë‹¨ì–´ ì¡´ì¬ ì—¬ë¶€(BoW, Bag of Words)** ë˜ëŠ” **ë¹ˆë„(TF)** ë¡œ ê°’ì„ ì±„ìš´ë‹¤.

---

#### ğŸ§® BoW (Bag of Words) ë°©ì‹

ë¬¸ì„œë¥¼ ë‹¨ì–´ì˜ ì§‘í•©ìœ¼ë¡œ ë‹¨ìˆœí™”í•˜ëŠ” ëª¨ë¸.
ë‹¨ì–´ì˜ ìˆœì„œ ì •ë³´ëŠ” ë¬´ì‹œë˜ë©°, **ë‹¨ì–´ì˜ ë“±ì¥ ì—¬ë¶€/ë¹ˆë„ë§Œ ê³ ë ¤.**

* **Unigram (1-gram):**
  `It was the best of times` â†’ `It`, `was`, `the`, `best`, `of`, `times`
* **Bigram (2-gram):**
  `It was the best of times` â†’ `It was`, `was the`, `the best`, `best of`, `of times`

> âœ… n-gram ìˆ˜ê°€ ì»¤ì§ˆìˆ˜ë¡ íŠ¹ì§• ì°¨ì›ì´ ì¦ê°€í•˜ë©°, ë³´ë‹¤ ì •êµí•œ ë¬¸ë§¥ í‘œí˜„ì´ ê°€ëŠ¥í•˜ì§€ë§Œ
> ì—°ì‚°ëŸ‰ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ë„ í•¨ê»˜ ì¦ê°€í•œë‹¤.

---

#### âš™ï¸ Sparse Embedding íŠ¹ì§• ìš”ì•½

| í•­ëª©                 | ì„¤ëª…                                           |
| ------------------ | -------------------------------------------- |
| **Embedding ì°¨ì› ìˆ˜** | ì „ì²´ ìš©ì–´ ìˆ˜ì™€ ë™ì¼ (terms = dimensions)             |
| **n-gram ì¦ê°€**      | ì°¨ì› ìˆ˜ ê¸‰ê²©íˆ ì¦ê°€                                  |
| **ì¥ì **             | íŠ¹ì • ë‹¨ì–´ overlapì„ ì •í™•íˆ íŒŒì•… ê°€ëŠ¥                     |
| **ë‹¨ì **             | ìœ ì‚¬ ì˜ë¯¸ ë‹¨ì–´ ê°„(ì˜ˆ: â€œbuyâ€ vs â€œpurchaseâ€) ì˜ë¯¸ì  ë¹„êµ ë¶ˆê°€ |

> ğŸ’¡ *ìš”ì•½:* Sparse Embeddingì€ â€œë‹¨ì–´ì˜ ì¡´ì¬ ì—¬ë¶€â€ë¥¼ ì§ì ‘ì ìœ¼ë¡œ í‘œí˜„í•˜ì§€ë§Œ,
> **ì˜ë¯¸ì  ìœ ì‚¬ì„±(semantic similarity)** ì€ ë°˜ì˜í•˜ì§€ ëª»í•œë‹¤.

---

## 3ï¸âƒ£ TF-IDF (Term Frequency â€“ Inverse Document Frequency)

Sparse Embeddingì˜ ëŒ€í‘œì  ìˆ˜ì¹˜í™” ë°©ë²• ì¤‘ í•˜ë‚˜ê°€ **TF-IDF** ì´ë‹¤.

---

### âš™ï¸ ì •ì˜

TF-IDFëŠ” ë¬¸ì„œ ë‚´ íŠ¹ì • ë‹¨ì–´ì˜ **ì¤‘ìš”ë„(weight)** ë¥¼ ìˆ˜ì¹˜ë¡œ í‘œí˜„í•œë‹¤.

> **TF (Term Frequency)**: ë‹¨ì–´ê°€ ë¬¸ì„œì— ì–¼ë§ˆë‚˜ ìì£¼ ë“±ì¥í•˜ëŠ”ê°€
> **IDF (Inverse Document Frequency)**: ë‹¨ì–´ê°€ ì „ì²´ ë¬¸ì„œì—ì„œ ì–¼ë§ˆë‚˜ í¬ê·€í•œê°€

ë‘ ê°’ì„ ê³±í•˜ì—¬ íŠ¹ì • ë¬¸ì„œ ë‚´ ë‹¨ì–´ì˜ â€œì •ë³´ëŸ‰â€ì„ ì¸¡ì •í•œë‹¤.

---

### ğŸ§© Term Frequency (TF)

> ë‹¨ì–´ê°€ íŠ¹ì • ë¬¸ì„œ ë‚´ ë“±ì¥í•œ ë¹ˆë„

* **Raw Count:** ë“±ì¥ íšŸìˆ˜
* **Length-normalized:** ë¬¸ì„œ ê¸¸ì´ë¡œ ì •ê·œí™”

$$
\mathrm{TF}(t, d) = \frac{\text{ë‹¨ì–´ tì˜ ë“±ì¥ íšŸìˆ˜}}{\text{ë¬¸ì„œ dì˜ ì „ì²´ ë‹¨ì–´ ìˆ˜}}
$$

> ë‹¤ë¥¸ ë³€í˜• ë°©ì‹: binary(ì¡´ì¬ ì—¬ë¶€), log-scaling ë“±

---

### ğŸ” Inverse Document Frequency (IDF)

> ë‹¨ì–´ì˜ ì •ë³´ëŸ‰ì„ ë‚˜íƒ€ë‚´ë©°, **ëª¨ë“  ë¬¸ì„œì— í”í•˜ê²Œ ë“±ì¥í• ìˆ˜ë¡ ê°€ì¹˜ëŠ” ë‚®ë‹¤.**

* **N:** ì „ì²´ ë¬¸ì„œ ìˆ˜
* **DF(t):** ë‹¨ì–´ *t*ê°€ ë“±ì¥í•œ ë¬¸ì„œ ìˆ˜

$$
\mathrm{IDF}(t) = \log \left( \frac{N}{1 + \mathrm{DF}(t)} \right)
$$

> â€œtheâ€, â€œisâ€, â€œandâ€ì²˜ëŸ¼ ëŒ€ë¶€ë¶„ ë¬¸ì„œì— ì¡´ì¬í•˜ëŠ” ë‹¨ì–´ëŠ” IDFê°€ 0ì— ê°€ê¹Œì›€
> ë°˜ë©´ â€œBTSâ€, â€œHeisenbergâ€ì²˜ëŸ¼ í¬ê·€ ë‹¨ì–´ëŠ” ë†’ì€ IDF ê°’ì„ ê°€ì§.

---

### ğŸ’¡ TF-IDF ê²°í•©

$$
\mathrm{TF\text{-}IDF}(t, d) = \mathrm{TF}(t, d) \times \mathrm{IDF}(t)
$$

| ë‹¨ì–´    | TF | IDF | TF-IDF | í•´ì„     |
| ----- | -- | --- | ------ | ------ |
| `the` | ë†’ìŒ | ë‚®ìŒ  | ë‚®ìŒ     | ì •ë³´ëŸ‰ ë‚®ìŒ |
| `BTS` | ë‚®ìŒ | ë†’ìŒ  | ë†’ìŒ     | ì¤‘ìš” ë‹¨ì–´  |

---

### ğŸ“˜ TF-IDF ê³„ì‚° ì˜ˆì‹œ

| ë¬¸ì„œ ì œëª© | ë¬¸ì„œ ë‚´ìš©                     |
| ----- | ------------------------- |
| ìŒì‹    | ì£¼ì—°ì€ ê³¼ì œë¥¼ ì¢‹ì•„í•œë‹¤              |
| ìš´ë™    | ì£¼ì—°ì€ ë†êµ¬ì™€ ì¶•êµ¬ë¥¼ ì¢‹ì•„í•œë‹¤          |
| ì˜í™”    | ì£¼ì—°ì€ ì–´ë²¤ì ¸ìŠ¤ë¥¼ ê°€ì¥ ì¢‹ì•„í•œë‹¤         |
| ìŒì•…    | ì£¼ì—°ì€ BTSì˜ ë·”ê°€ ê°€ì¥ ì˜ìƒê²¼ë‹¤ê³  ìƒê°í•œë‹¤ |

1. ê° ë¬¸ì„œì—ì„œ ë‹¨ì–´ ë“±ì¥ ë¹ˆë„ ê³„ì‚° (TF)
2. ì „ì²´ ë¬¸ì„œ ë‚´ ë“±ì¥ ë¬¸ì„œ ìˆ˜ ê¸°ë°˜ IDF ê³„ì‚°
3. ë‘ ê°’ ê³±í•´ ë¬¸ì„œë³„ **TF-IDF ë²¡í„°** ìƒì„±
4. Queryì˜ TF-IDFì™€ ë¬¸ì„œì˜ TF-IDF ë²¡í„° ê°„ **ìœ ì‚¬ë„(cosine similarity)** ê³„ì‚°

---

### ğŸ§  TF-IDF ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ ë‹¨ê³„

1. ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆì˜ë¥¼ í† í°í™”
2. ê¸°ì¡´ ì‚¬ì „ì— ì—†ëŠ” í† í° ì œê±°
3. ì§ˆì˜ë¥¼ í•˜ë‚˜ì˜ â€œë¬¸ì„œâ€ë¡œ ê°„ì£¼í•˜ê³  TF-IDF ê³„ì‚°
4. ì§ˆì˜ TF-IDFì™€ ê° ë¬¸ì„œì˜ TF-IDF ë²¡í„° ë‚´ì  ê³„ì‚°
5. ìœ ì‚¬ë„ ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ë¬¸ì„œë¥¼ ê²°ê³¼ë¡œ ë°˜í™˜

> ì˜ˆì‹œ
> **Query:** â€œì£¼ì—°ì€ BTSì˜ ëˆ„êµ¬ë¥¼ ê°€ì¥ ì˜ìƒê²¼ë‹¤ê³  ìƒê°í•˜ë‚˜?â€
> â†’ ê°€ì¥ ë†’ì€ TF-IDF ìœ ì‚¬ë„ë¥¼ ê°€ì§„ ë¬¸ì„œ: â€œìŒì•…â€

---

### ğŸ“Š TF-IDFì˜ í•œê³„ì™€ ê°œì„  (BM25)

**BM25**ëŠ” TF-IDFì˜ í™•ì¥ëœ í˜•íƒœë¡œ,
ë¬¸ì„œ ê¸¸ì´ì™€ ë‹¨ì–´ì˜ í¬í™” ë¹ˆë„(saturation)ë¥¼ í•¨ê»˜ ê³ ë ¤í•œë‹¤.

| íŠ¹ì§•           | ì„¤ëª…                     |
| ------------ | ---------------------- |
| **ë¬¸ì„œ ê¸¸ì´ ë³´ì •** | ì§§ì€ ë¬¸ì„œì—ì„œì˜ ë“±ì¥ ë‹¨ì–´ì— ê°€ì¤‘ì¹˜ ë¶€ì—¬ |
| **TF í•œê³„ ì„¤ì •** | ë„ˆë¬´ ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ì— í¬í™”ê°’ ì ìš©  |
| **í˜„ì—… ì ìš© ì˜ˆì‹œ** | ê²€ìƒ‰ì—”ì§„, ì¶”ì²œ ì‹œìŠ¤í…œ, ë…¼ë¬¸ ê²€ìƒ‰ ë“±  |

> ğŸ“Œ *Tip:* Pyserini ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ BM25 êµ¬í˜„ìœ¼ë¡œ ì‹¤í—˜ ê°€ëŠ¥
> [Pyserini BM25 Example (MS MARCO)](https://github.com/castorini/pyserini/blob/master/docs/experiments-msmarco-passage.md)

---


## ğŸš€ ì‹¤ë¬´ ë° í”„ë¡œì íŠ¸ í™œìš© í¬ì¸íŠ¸

1. **TF-IDF + Cosine Similarity**ë¡œ ê°„ë‹¨í•œ ë¬¸ì„œ ê²€ìƒ‰ê¸° êµ¬í˜„ ê°€ëŠ¥
2. **BM25**ëŠ” í˜„ì¬ë„ ê²€ìƒ‰ì—”ì§„ ê¸°ë³¸ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì‚¬ìš©
3. Sparse Embeddingì€ **Dense Retrieval (BERT-based)** ëª¨ë¸ê³¼ ë¹„êµ ì‹¤í—˜ ì‹œ baselineìœ¼ë¡œ ìœ ìš©
4. KorQuAD, MS MARCO ë“± QA ë°ì´í„°ì…‹ì—ì„œ **retriever ëª¨ë¸ ì‚¬ì „ ë‹¨ê³„ë¡œ í™œìš©** ê°€ëŠ¥

---

ğŸ“š **ì°¸ê³ ë¬¸í—Œ ë° ì¶œì²˜**

* Manning et al., *Introduction to Information Retrieval* (Cambridge University Press, 2008)
* Kim et al., *Research paper classification systems based on TF-IDF and LDA schemes*, *HCIS Journal*, 2019
* [Pyserini GitHub Repository](https://github.com/castorini/pyserini)
* [Wikipedia: TFâ€“IDF](https://en.wikipedia.org/wiki/Tfâ€“idf)
