# | Passage Retrieval â€“ ì˜ë¯¸ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ (Dense Embedding)

## ğŸ§¾ í•µì‹¬ ì •ë¦¬ | Sparse vs Dense

| í•­ëª©    | Sparse Embedding | Dense Embedding    |
| ----- | ---------------- | ------------------ |
| ì˜ˆì‹œ    | TF-IDF, BM25     | BERT, DPR, ColBERT |
| í‘œí˜„ ê¸°ë°˜ | ë‹¨ì–´ ë¹ˆë„ ê¸°ë°˜         | ì˜ë¯¸ ê¸°ë°˜ ë²¡í„° ê³µê°„        |
| í•™ìŠµ    | ë¹„í•™ìŠµ (í†µê³„)         | í•™ìŠµ ê¸°ë°˜ (ì‹ ê²½ë§)        |
| í™•ì¥ì„±   | ìƒˆë¡œìš´ ë‹¨ì–´ ì¶”ê°€ ì‹œ ë¶ˆê°€   | ì¶”ê°€ í•™ìŠµìœ¼ë¡œ ë³´ì™„ ê°€ëŠ¥      |
| ì í•© ë¬¸ì œ | ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­       | ì˜ë¯¸ ìœ ì‚¬ ê²€ìƒ‰, ì§ˆì˜ì‘ë‹µ     |

---

> **í•µì‹¬ ì£¼ì œ:** Sparse ë°©ì‹ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ ë‹¨ì–´ ì˜ë¯¸ ê³µê°„ì„ í•™ìŠµí•´ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•˜ëŠ” Dense Embedding ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰

---

## 1ï¸âƒ£ Introduction to Dense Embedding

**ì¡°ë°€í•œ ì„ë² ë”© (Dense Embedding)**

### ğŸ’¡ Dense Embeddingì´ë€?

* Sparse representation (ì˜ˆ: TF-IDF) ê³¼ ë³´ì™„ì ì¸ ê°œë…
* ì‘ì€ ì°¨ì›ì˜ ê³ ë°€ë„ ë²¡í„° (length â‰ˆ 50 ~ 1000)
* ê° ì°¨ì›ì´ íŠ¹ì • ë‹¨ì–´ (term)ì— ì§ì ‘ ëŒ€ì‘í•˜ì§€ ì•ŠìŒ
* ëŒ€ë¶€ë¶„ì˜ ìš”ì†Œê°€ **non-zero ê°’**ì„ ê°€ì§
* í•™ìŠµì„ í†µí•´ **ì˜ë¯¸ì  ì—°ê´€ì„±**ì„ ë°˜ì˜

| êµ¬ë¶„ | Sparse Embedding  | Dense Embedding  |
| -- | ----------------- | ---------------- |
| ì°¨ì› | ë§¤ìš° ë†’ìŒ (ìˆ˜ë§Œ ì°¨ì›)     | ë‚®ìŒ (ìˆ˜ë°± ì°¨ì›)       |
| ìš”ì†Œ | ëŒ€ë¶€ë¶„ 0             | ëŒ€ë¶€ë¶„ non-zero     |
| íŠ¹ì§• | ë‹¨ì–´ ë‹¨ìœ„ ì¼ì¹˜ ê¸°ë°˜       | ì˜ë¯¸ ê¸°ë°˜ ì—°ê´€ì„± ë°˜ì˜     |
| í•™ìŠµ | ê³ ì •ëœ ë²¡í„°            | ì¶”ê°€ í•™ìŠµ ê°€ëŠ¥         |
| ì¥ì  | ëª…í™•í•œ term ë§¤ì¹­ ì„±ëŠ¥ ìš°ìˆ˜ | ìœ ì‚¬ ë‹¨ì–´ ê°„ ê´€ê³„ ì´í•´ ìš°ìˆ˜ |

> ğŸ“˜ ìš”ì•½: Dense Embeddingì€ â€œë¹„ìŠ·í•œ ì˜ë¯¸ì˜ ë‹¨ì–´ ë˜ëŠ” ë¬¸ì¥â€ì„ ë²¡í„° ê³µê°„ì—ì„œ ê°€ê¹Œì´ ìœ„ì¹˜ì‹œí‚¤ëŠ” ê²ƒì´ í•µì‹¬ì´ë‹¤.

---

## 2ï¸âƒ£ Training Dense Encoder

**Dense Encoder ëª¨ë¸ í•™ìŠµ ë° í›ˆë ¨ ë°©ë²•**

### ğŸ§  Dense Encoderë€?

* ë¬¸ì¥ì´ë‚˜ ë¬¸ì„œë¥¼ Dense Embedding ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ëª¨ë¸
* ì£¼ë¡œ **BERT**, RoBERTa ë“± PLM (Pre-trained Language Model) ì‚¬ìš©
* `[CLS]` í† í°ì˜ ì¶œë ¥ ë²¡í„°ë¥¼ ëŒ€í‘œ ê°’ìœ¼ë¡œ í™œìš©

```text
ì…ë ¥: [CLS] Query [SEP] Passage [SEP]
ì¶œë ¥: CLS í† í° ì„ë² ë”© (ë¬¸ì„œ/ì§ˆì˜ í‘œí˜„)
```

---

### ğŸ¯ í•™ìŠµ ëª©í‘œ

**ì—°ê´€ëœ question â€“ passage ìŒì€ ê°€ê¹ê²Œ**,
**ì—°ê´€ë˜ì§€ ì•Šì€ ìŒì€ ë©€ê²Œ** í•™ìŠµì‹œí‚´.

* ëª©ì  í•¨ìˆ˜(Objective): Positive passageì— ëŒ€í•œ Negative Log Likelihood (NLL) loss
* ê±°ë¦¬ ì²™ë„: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë˜ëŠ” ë‚´ì  (inner product)

---

### âš™ï¸ Negative Sampling

> ëª¨ë¸ì´ í˜¼ë™í•˜ì§€ ì•Šë„ë¡ ìœ ì‚¬í•˜ì§€ë§Œ ì •ë‹µì´ ì•„ë‹Œ ë¬¸ì¥ì„ ìƒ˜í”Œë§

* **Random Negatives:** Corpus ë‚´ ì„ì˜ì˜ ë¬¸ì„œ ì¶”ì¶œ
* **Hard Negatives:** TF-IDF ë“±ìœ¼ë¡œ ìœ ì‚¬ë„ê°€ ë†’ì§€ë§Œ ì •ë‹µì´ ì•„ë‹Œ ë¬¸ì„œ ì„ ì •

---

### ğŸ“ˆ í‰ê°€ ì§€í‘œ

**Top-k Retrieval Accuracy**

> ê²€ìƒ‰ëœ passage ìƒìœ„ kê°œ ì¤‘ ì‹¤ì œ ë‹µì„ í¬í•¨í•œ passageì˜ ë¹„ìœ¨

ì˜ˆ:
Top-5 accuracy = 5ê°œ ì¤‘ ì •ë‹µ passage 1ê°œ ì´ìƒ í¬í•¨ ì‹œ 1 / ì´ ì¿¼ë¦¬ ìˆ˜

---

## 3ï¸âƒ£ Passage Retrieval with Dense Encoder

**Dense Embedding ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰ íë¦„**

### ğŸ”„ Inference Flow

1. Passage ì „ì²´ë¥¼ Dense Encoderë¡œ ì„ë² ë”©í•˜ì—¬ ë²¡í„° ì €ì¥
2. ì‚¬ìš©ìì˜ Query ì—­ì‹œ ì„ë² ë”©
3. Query ë²¡í„°ì™€ ê°€ì¥ ê°€ê¹Œìš´ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë†’ì€) Passage íƒìƒ‰
4. ì„ íƒëœ Passageë¥¼ MRC ëª¨ë¸ì— ì…ë ¥í•˜ì—¬ ì •ë‹µ ìƒì„±

---

### ğŸ” From Retrieval to Open-Domain QA

* Dense Retrieverë¡œ ë¬¸ì„œë¥¼ ì„ íƒ
* ì„ íƒëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ **MRC ëª¨ë¸**ì´ ì„¸ë¶€ ë‹µë³€ ë„ì¶œ
* ì¦‰, â€œê²€ìƒ‰ â†’ ì´í•´ â†’ ì‘ë‹µâ€ì˜ 2-ë‹¨ê³„ Pipeline êµ¬ì¡°

---

### ğŸš€ Dense Encoding ì„±ëŠ¥ í–¥ìƒ ì „ëµ

1. **í•™ìŠµ ì „ëµ ê°œì„ ** â€” e.g. DPR (Dense Passage Retriever)
2. **ëª¨ë¸ ê°œì„ ** â€” ë” í° PLM (RoBERTa-large, E5 ë“±)
3. **ë°ì´í„° ê°œì„ ** â€” ë‹¤ì–‘í•œ domain ì¶”ê°€ ë° ì „ì²˜ë¦¬ ë³´ê°•

---

> âœ… Dense Embeddingì˜ í•µì‹¬ì€ ë‹¨ì–´ì˜ â€œí‘œë©´ì  ì¼ì¹˜â€ ê°€ ì•„ë‹Œ
> â€œì˜ë¯¸ì  ìœ ì‚¬ì„±â€ ì„ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•œë‹¤ëŠ” ê²ƒì´ë‹¤.
> ì´ ê°œë…ì€ ì´í›„ì˜ Open-Domain QA, Retrieval-Augmented Generation (RAG) ë“±ìœ¼ë¡œ í™•ì¥ëœë‹¤.
